{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joyle\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  #畫圖形\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras_self_attention import SeqSelfAttention\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_data(Data):\n",
    "    d = Data[\"Date\"]\n",
    "    d = pd.to_datetime(d)\n",
    "\n",
    "    data = Data[\"Price\"]\n",
    "    data.index = pd.Index(d)\n",
    "\n",
    "    return data\n",
    "\n",
    "def missing_value():\n",
    "    SAT = pd.date_range(start = '01/01/2016', end = '03/31/2019', freq='W-SAT')\n",
    "\n",
    "    SUN = pd.date_range(start = '01/01/2016', end = '05/31/2018', freq='W-SUN')\n",
    "\n",
    "    s1 = pd.Series([np.nan]*len(SAT) ,index=SAT)\n",
    "    s2 = pd.Series([np.nan]*len(SUN) ,index=SUN)\n",
    "    \n",
    "    return s1, s2\n",
    "    \n",
    "def supplement_data(data):\n",
    "    s1, s2 = missing_value()\n",
    "    \n",
    "    data = data.append(s1)\n",
    "    data = data.append(s2)\n",
    "    \n",
    "    data.sort_index(inplace=True)\n",
    "    \n",
    "    for j in range(len(data)):\n",
    "        null_value = data[data.isnull().values == True]\n",
    "        if len(null_value) != 0:\n",
    "            for i in range(len(null_value)):\n",
    "                if math.isnan(data[null_value.index[i]+timedelta(-1)]) == False:\n",
    "                    if math.isnan(data[null_value.index[i]+timedelta(1)]) == False: \n",
    "                        data[null_value.index[i]] = (data[null_value.index[i]+timedelta(-1)]+data[null_value.index[i]+timedelta(1)])/2\n",
    "            data = data.fillna(method = 'ffill', limit = 1)\n",
    "            data = data.fillna(method = 'bfill', limit = 1)            \n",
    "        else:\n",
    "            break\n",
    "    \n",
    "            \n",
    "    return data\n",
    "\n",
    "def change_slope(train):\n",
    "    slope = []\n",
    "    for i in range(len(train)-1):\n",
    "        slo = train[i+1]/train[i]\n",
    "        slope.append(slo)\n",
    "\n",
    "    return slope\n",
    "\n",
    "def split(data):\n",
    "    train = data[:'2018-12-31']\n",
    "    train_slope = change_slope(train)\n",
    "    train_slope = scale(train_slope)\n",
    "    train_slope = np.insert(train_slope,0,1)\n",
    "    \n",
    "    true = data['2019-01-01':]\n",
    "    \n",
    "    test = data['2018-12-25':]\n",
    "    test_slope_data = data['2018-12-24':]\n",
    "    test_slope = change_slope(test_slope_data)\n",
    "    test_slope = scale(test_slope)\n",
    "    \n",
    "    return train, true, test, train_slope, test_slope\n",
    "\n",
    "def train_data(train, train_slope):\n",
    "    \n",
    "    # data 分組\n",
    "    x_slope_train = []\n",
    "    x_data_train = []\n",
    "    y_data_train = []\n",
    "    for i in range(7, len(train)):\n",
    "        x_data_train.append(train[i-7:i])\n",
    "        y_data_train.append(train[i])\n",
    "    \n",
    "    for i in range(7,len(train_slope)):\n",
    "        x_slope_train.append(train_slope[i-7:i])    \n",
    "    \n",
    "    x_data_train, y_data_train, x_slope_train = np.array(x_data_train), np.array(y_data_train), np.array(x_slope_train)\n",
    "    \n",
    "    x_data_train = x_data_train.reshape(x_data_train.shape[0], x_data_train.shape[1], 1)\n",
    "    x_slope_train = x_slope_train.reshape(x_slope_train.shape[0], x_slope_train.shape[1], 1)\n",
    "\n",
    "    x_train = np.concatenate([x_data_train, x_slope_train], 2)\n",
    "    \n",
    "    return x_train, y_data_train\n",
    "\n",
    "def model(x_train, y_train):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(50, input_shape = (x_train.shape[1], 2), activation='relu', return_sequences = True))\n",
    "    model.add(SeqSelfAttention(attention_activation='relu'))\n",
    "    model.add(LSTM(units = 50))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "\n",
    "    train_history = model.fit(x_train, y_train, epochs = 1000, batch_size = 200, validation_split=0.2)\n",
    "    \n",
    "    return model, train_history\n",
    "\n",
    "def show_train_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='upper right')\n",
    "    plt.show()\n",
    "    \n",
    "def predict(test, test_slope):\n",
    "    \n",
    "    # data 分組\n",
    "    x_data_test = []\n",
    "    for i in range(7, len(test)):\n",
    "        x_data_test.append(test[i-7:i])\n",
    "    x_data_test = np.array(x_data_test)\n",
    "    \n",
    "    # slope 分組\n",
    "    x_slope_test = []\n",
    "    for i in range(7, len(test_slope)):\n",
    "        x_slope_test.append(test_slope[i-7:i])\n",
    "    x_slope_test = np.array(x_slope_test)\n",
    "    \n",
    "    x_data_test = x_data_test.reshape(x_data_test.shape[0], x_data_test.shape[1], 1) \n",
    "    x_slope_test = x_slope_test.reshape(x_slope_test.shape[0], x_slope_test.shape[1], 1) \n",
    "\n",
    "    x_test = np.concatenate([x_data_test, x_slope_test], 2)\n",
    "    \n",
    "    predicted_data = model.predict(x_test)\n",
    "    \n",
    "    predicted_data = predicted_data.ravel() #拉成一維\n",
    "    predicted_data = pd.Series(predicted_data)\n",
    "    \n",
    "    #預測的日期\n",
    "    pred_time = pd.date_range(start = '01/01/2019', end = '03/31/2019')\n",
    "        \n",
    "    predicted_data.index = pd.Index(pred_time)\n",
    "    predicted_data = pd.DataFrame(predicted_data , columns=['現金'])\n",
    "    \n",
    "    return predicted_data\n",
    "\n",
    "def plot_data(true_data, predicted_data):\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(predicted_data.index, true_data, color = 'cornflowerblue', marker = 'o', label='True')\n",
    "    plt.plot(predicted_data.index, predicted_data, color = 'lightcoral', marker = 'o', label='Predict')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def rmse(test, true):\n",
    "    predicted_data = predict(test, test_slope)\n",
    "    \n",
    "    #drop value\n",
    "    SAT = pd.date_range(start = '01/01/2019', end = '03/31/2019', freq='W-SAT')\n",
    "    \n",
    "    predicted_data = predicted_data.drop(SAT)\n",
    "    \n",
    "    true = true.drop(SAT)\n",
    "    true = pd.DataFrame(true , columns=['現金'])\n",
    "    \n",
    "    RMSE = np.sqrt(((predicted_data-true)**2).sum()/true.size)\n",
    "    MAPE = abs((true-predicted_data)/true).sum()/len(true)\n",
    "    \n",
    "    return RMSE, MAPE, predicted_data , true\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_excel(\"c:/python/AUD-USD/AUD_USD.xlsx\",index_col=False)\n",
    "data = sort_data(Data)\n",
    "data = supplement_data(data)\n",
    "train, true, test, train_slope, test_slope = split(data)\n",
    "x_train , y_train = train_data(train, train_slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\joyle\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1242: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\joyle\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1208: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\joyle\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1344: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Train on 871 samples, validate on 218 samples\n",
      "Epoch 1/1000\n",
      "871/871 [==============================] - 1s 898us/step - loss: 0.4577 - val_loss: 0.3010\n",
      "Epoch 2/1000\n",
      "871/871 [==============================] - 0s 113us/step - loss: 0.2628 - val_loss: 0.1244\n",
      "Epoch 3/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 0.0827 - val_loss: 0.0054\n",
      "Epoch 4/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 0.0286 - val_loss: 0.0421\n",
      "Epoch 5/1000\n",
      "871/871 [==============================] - 0s 114us/step - loss: 0.0379 - val_loss: 0.0046\n",
      "Epoch 6/1000\n",
      "871/871 [==============================] - 0s 118us/step - loss: 0.0090 - val_loss: 0.0085\n",
      "Epoch 7/1000\n",
      "871/871 [==============================] - 0s 112us/step - loss: 0.0147 - val_loss: 0.0095\n",
      "Epoch 8/1000\n",
      "871/871 [==============================] - 0s 112us/step - loss: 0.0110 - val_loss: 0.0025\n",
      "Epoch 9/1000\n",
      "871/871 [==============================] - 0s 111us/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 10/1000\n",
      "871/871 [==============================] - 0s 110us/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 11/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 12/1000\n",
      "871/871 [==============================] - 0s 116us/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 13/1000\n",
      "871/871 [==============================] - 0s 123us/step - loss: 0.0031 - val_loss: 8.6251e-04\n",
      "Epoch 14/1000\n",
      "871/871 [==============================] - 0s 113us/step - loss: 0.0024 - val_loss: 7.9808e-04\n",
      "Epoch 15/1000\n",
      "871/871 [==============================] - 0s 121us/step - loss: 0.0021 - val_loss: 9.4718e-04\n",
      "Epoch 16/1000\n",
      "871/871 [==============================] - 0s 121us/step - loss: 0.0019 - val_loss: 6.6502e-04\n",
      "Epoch 17/1000\n",
      "871/871 [==============================] - 0s 137us/step - loss: 0.0016 - val_loss: 4.7501e-04\n",
      "Epoch 18/1000\n",
      "871/871 [==============================] - 0s 116us/step - loss: 0.0014 - val_loss: 4.3146e-04\n",
      "Epoch 19/1000\n",
      "871/871 [==============================] - 0s 112us/step - loss: 0.0013 - val_loss: 4.8475e-04\n",
      "Epoch 20/1000\n",
      "871/871 [==============================] - 0s 117us/step - loss: 0.0011 - val_loss: 4.4240e-04\n",
      "Epoch 21/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 9.6716e-04 - val_loss: 3.5024e-04\n",
      "Epoch 22/1000\n",
      "871/871 [==============================] - 0s 106us/step - loss: 8.5242e-04 - val_loss: 2.8961e-04\n",
      "Epoch 23/1000\n",
      "871/871 [==============================] - 0s 101us/step - loss: 7.4227e-04 - val_loss: 3.0414e-04\n",
      "Epoch 24/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.4680e-04 - val_loss: 2.9807e-04\n",
      "Epoch 25/1000\n",
      "871/871 [==============================] - 0s 100us/step - loss: 5.6639e-04 - val_loss: 2.6606e-04\n",
      "Epoch 26/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.9537e-04 - val_loss: 2.2891e-04\n",
      "Epoch 27/1000\n",
      "871/871 [==============================] - 0s 99us/step - loss: 4.3054e-04 - val_loss: 2.3404e-04\n",
      "Epoch 28/1000\n",
      "871/871 [==============================] - 0s 102us/step - loss: 3.7807e-04 - val_loss: 2.0809e-04\n",
      "Epoch 29/1000\n",
      "871/871 [==============================] - 0s 89us/step - loss: 3.2963e-04 - val_loss: 2.2038e-04\n",
      "Epoch 30/1000\n",
      "871/871 [==============================] - 0s 100us/step - loss: 2.8943e-04 - val_loss: 1.9137e-04\n",
      "Epoch 31/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.6110e-04 - val_loss: 1.8135e-04\n",
      "Epoch 32/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.2820e-04 - val_loss: 2.2086e-04\n",
      "Epoch 33/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 2.0686e-04 - val_loss: 2.1229e-04\n",
      "Epoch 34/1000\n",
      "871/871 [==============================] - 0s 98us/step - loss: 1.8769e-04 - val_loss: 1.7057e-04\n",
      "Epoch 35/1000\n",
      "871/871 [==============================] - 0s 101us/step - loss: 1.7575e-04 - val_loss: 1.7255e-04\n",
      "Epoch 36/1000\n",
      "871/871 [==============================] - 0s 105us/step - loss: 1.6089e-04 - val_loss: 2.2078e-04\n",
      "Epoch 37/1000\n",
      "871/871 [==============================] - 0s 119us/step - loss: 1.5337e-04 - val_loss: 2.1664e-04\n",
      "Epoch 38/1000\n",
      "871/871 [==============================] - 0s 101us/step - loss: 1.4407e-04 - val_loss: 1.8305e-04\n",
      "Epoch 39/1000\n",
      "871/871 [==============================] - 0s 91us/step - loss: 1.3907e-04 - val_loss: 1.8151e-04\n",
      "Epoch 40/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.3388e-04 - val_loss: 2.1871e-04\n",
      "Epoch 41/1000\n",
      "871/871 [==============================] - 0s 100us/step - loss: 1.3061e-04 - val_loss: 2.1301e-04\n",
      "Epoch 42/1000\n",
      "871/871 [==============================] - 0s 99us/step - loss: 1.2656e-04 - val_loss: 1.9139e-04\n",
      "Epoch 43/1000\n",
      "871/871 [==============================] - 0s 157us/step - loss: 1.2460e-04 - val_loss: 1.9161e-04\n",
      "Epoch 44/1000\n",
      "871/871 [==============================] - 0s 131us/step - loss: 1.2265e-04 - val_loss: 2.0405e-04\n",
      "Epoch 45/1000\n",
      "871/871 [==============================] - 0s 125us/step - loss: 1.2076e-04 - val_loss: 2.1208e-04\n",
      "Epoch 46/1000\n",
      "871/871 [==============================] - 0s 120us/step - loss: 1.1927e-04 - val_loss: 2.0472e-04\n",
      "Epoch 47/1000\n",
      "871/871 [==============================] - 0s 112us/step - loss: 1.1779e-04 - val_loss: 1.8995e-04\n",
      "Epoch 48/1000\n",
      "871/871 [==============================] - 0s 118us/step - loss: 1.1730e-04 - val_loss: 2.0142e-04\n",
      "Epoch 49/1000\n",
      "871/871 [==============================] - 0s 113us/step - loss: 1.1620e-04 - val_loss: 2.2493e-04\n",
      "Epoch 50/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.1430e-04 - val_loss: 1.9174e-04\n",
      "Epoch 51/1000\n",
      "871/871 [==============================] - 0s 139us/step - loss: 1.1361e-04 - val_loss: 1.9466e-04\n",
      "Epoch 52/1000\n",
      "871/871 [==============================] - 0s 118us/step - loss: 1.1207e-04 - val_loss: 2.1847e-04\n",
      "Epoch 53/1000\n",
      "871/871 [==============================] - 0s 116us/step - loss: 1.1141e-04 - val_loss: 2.0810e-04\n",
      "Epoch 54/1000\n",
      "871/871 [==============================] - 0s 112us/step - loss: 1.1034e-04 - val_loss: 1.8937e-04\n",
      "Epoch 55/1000\n",
      "871/871 [==============================] - 0s 111us/step - loss: 1.0928e-04 - val_loss: 2.0650e-04\n",
      "Epoch 56/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.0824e-04 - val_loss: 2.1547e-04\n",
      "Epoch 57/1000\n",
      "871/871 [==============================] - 0s 111us/step - loss: 1.0735e-04 - val_loss: 1.9854e-04\n",
      "Epoch 58/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.0673e-04 - val_loss: 1.9388e-04\n",
      "Epoch 59/1000\n",
      "871/871 [==============================] - 0s 110us/step - loss: 1.0556e-04 - val_loss: 2.2095e-04\n",
      "Epoch 60/1000\n",
      "871/871 [==============================] - 0s 112us/step - loss: 1.0499e-04 - val_loss: 1.9754e-04\n",
      "Epoch 61/1000\n",
      "871/871 [==============================] - 0s 113us/step - loss: 1.0414e-04 - val_loss: 1.9320e-04\n",
      "Epoch 62/1000\n",
      "871/871 [==============================] - 0s 110us/step - loss: 1.0312e-04 - val_loss: 2.1166e-04\n",
      "Epoch 63/1000\n",
      "871/871 [==============================] - 0s 110us/step - loss: 1.0226e-04 - val_loss: 1.9831e-04\n",
      "Epoch 64/1000\n",
      "871/871 [==============================] - 0s 110us/step - loss: 1.0184e-04 - val_loss: 1.9014e-04\n",
      "Epoch 65/1000\n",
      "871/871 [==============================] - 0s 119us/step - loss: 1.0084e-04 - val_loss: 2.1836e-04\n",
      "Epoch 66/1000\n",
      "871/871 [==============================] - 0s 123us/step - loss: 1.0044e-04 - val_loss: 1.9370e-04\n",
      "Epoch 67/1000\n",
      "871/871 [==============================] - 0s 119us/step - loss: 9.9467e-05 - val_loss: 1.9079e-04\n",
      "Epoch 68/1000\n",
      "871/871 [==============================] - 0s 113us/step - loss: 9.8374e-05 - val_loss: 2.0514e-04\n",
      "Epoch 69/1000\n",
      "871/871 [==============================] - 0s 113us/step - loss: 9.8109e-05 - val_loss: 1.9960e-04\n",
      "Epoch 70/1000\n",
      "871/871 [==============================] - 0s 113us/step - loss: 9.7174e-05 - val_loss: 1.8997e-04\n",
      "Epoch 71/1000\n",
      "871/871 [==============================] - 0s 113us/step - loss: 9.6668e-05 - val_loss: 1.9010e-04\n",
      "Epoch 72/1000\n",
      "871/871 [==============================] - 0s 124us/step - loss: 9.5961e-05 - val_loss: 1.9912e-04\n",
      "Epoch 73/1000\n",
      "871/871 [==============================] - 0s 117us/step - loss: 9.5581e-05 - val_loss: 2.0273e-04\n",
      "Epoch 74/1000\n",
      "871/871 [==============================] - 0s 111us/step - loss: 9.4664e-05 - val_loss: 1.8275e-04\n",
      "Epoch 75/1000\n",
      "871/871 [==============================] - 0s 117us/step - loss: 9.4805e-05 - val_loss: 1.9492e-04\n",
      "Epoch 76/1000\n",
      "871/871 [==============================] - 0s 118us/step - loss: 9.3905e-05 - val_loss: 2.0676e-04\n",
      "Epoch 77/1000\n",
      "871/871 [==============================] - 0s 111us/step - loss: 9.3302e-05 - val_loss: 1.7979e-04\n",
      "Epoch 78/1000\n",
      "871/871 [==============================] - 0s 118us/step - loss: 9.3015e-05 - val_loss: 2.0355e-04\n",
      "Epoch 79/1000\n",
      "871/871 [==============================] - 0s 113us/step - loss: 9.2314e-05 - val_loss: 1.9151e-04\n",
      "Epoch 80/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 9.1516e-05 - val_loss: 1.9729e-04\n",
      "Epoch 81/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 9.1100e-05 - val_loss: 1.9649e-04\n",
      "Epoch 82/1000\n",
      "871/871 [==============================] - 0s 117us/step - loss: 9.0685e-05 - val_loss: 2.0003e-04\n",
      "Epoch 83/1000\n",
      "871/871 [==============================] - 0s 119us/step - loss: 9.0257e-05 - val_loss: 1.9903e-04\n",
      "Epoch 84/1000\n",
      "871/871 [==============================] - 0s 111us/step - loss: 8.9890e-05 - val_loss: 1.9078e-04\n",
      "Epoch 85/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 9.0213e-05 - val_loss: 1.7768e-04\n",
      "Epoch 86/1000\n",
      "871/871 [==============================] - 0s 94us/step - loss: 8.8527e-05 - val_loss: 2.1179e-04\n",
      "Epoch 87/1000\n",
      "871/871 [==============================] - 0s 122us/step - loss: 8.9622e-05 - val_loss: 2.0243e-04\n",
      "Epoch 88/1000\n",
      "871/871 [==============================] - 0s 107us/step - loss: 8.8428e-05 - val_loss: 1.7928e-04\n",
      "Epoch 89/1000\n",
      "871/871 [==============================] - 0s 129us/step - loss: 8.7354e-05 - val_loss: 2.0897e-04\n",
      "Epoch 90/1000\n",
      "871/871 [==============================] - 0s 113us/step - loss: 8.7401e-05 - val_loss: 1.8722e-04\n",
      "Epoch 91/1000\n",
      "871/871 [==============================] - 0s 99us/step - loss: 8.6697e-05 - val_loss: 1.8529e-04\n",
      "Epoch 92/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 8.6426e-05 - val_loss: 1.9153e-04\n",
      "Epoch 93/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 8.5919e-05 - val_loss: 1.9289e-04\n",
      "Epoch 94/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 8.5908e-05 - val_loss: 1.8510e-04\n",
      "Epoch 95/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 8.5298e-05 - val_loss: 1.9105e-04\n",
      "Epoch 96/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 8.4862e-05 - val_loss: 1.8895e-04\n",
      "Epoch 97/1000\n",
      "871/871 [==============================] - 0s 121us/step - loss: 8.4454e-05 - val_loss: 1.8589e-04\n",
      "Epoch 98/1000\n",
      "871/871 [==============================] - 0s 96us/step - loss: 8.4127e-05 - val_loss: 1.8578e-04\n",
      "Epoch 99/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 8.3848e-05 - val_loss: 1.8179e-04\n",
      "Epoch 100/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 8.3315e-05 - val_loss: 1.9877e-04\n",
      "Epoch 101/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 8.3184e-05 - val_loss: 1.7536e-04\n",
      "Epoch 102/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 8.4208e-05 - val_loss: 1.6908e-04\n",
      "Epoch 103/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 8.2427e-05 - val_loss: 2.0383e-04\n",
      "Epoch 104/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 8.2742e-05 - val_loss: 1.7589e-04\n",
      "Epoch 105/1000\n",
      "871/871 [==============================] - 0s 118us/step - loss: 8.2624e-05 - val_loss: 1.7743e-04\n",
      "Epoch 106/1000\n",
      "871/871 [==============================] - 0s 109us/step - loss: 8.2604e-05 - val_loss: 1.9642e-04\n",
      "Epoch 107/1000\n",
      "871/871 [==============================] - 0s 112us/step - loss: 8.1284e-05 - val_loss: 1.6312e-04\n",
      "Epoch 108/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 8.1364e-05 - val_loss: 2.0151e-04\n",
      "Epoch 109/1000\n",
      "871/871 [==============================] - 0s 116us/step - loss: 8.0860e-05 - val_loss: 1.7501e-04\n",
      "Epoch 110/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 8.0264e-05 - val_loss: 1.9270e-04\n",
      "Epoch 111/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 8.0142e-05 - val_loss: 1.8617e-04\n",
      "Epoch 112/1000\n",
      "871/871 [==============================] - 0s 116us/step - loss: 8.0184e-05 - val_loss: 1.7284e-04\n",
      "Epoch 113/1000\n",
      "871/871 [==============================] - 0s 103us/step - loss: 7.9299e-05 - val_loss: 2.0122e-04\n",
      "Epoch 114/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 7.9523e-05 - val_loss: 1.8028e-04\n",
      "Epoch 115/1000\n",
      "871/871 [==============================] - 0s 112us/step - loss: 7.8656e-05 - val_loss: 1.7116e-04\n",
      "Epoch 116/1000\n",
      "871/871 [==============================] - 0s 93us/step - loss: 7.8330e-05 - val_loss: 1.9313e-04\n",
      "Epoch 117/1000\n",
      "871/871 [==============================] - 0s 123us/step - loss: 7.8427e-05 - val_loss: 1.8852e-04\n",
      "Epoch 118/1000\n",
      "871/871 [==============================] - 0s 103us/step - loss: 7.7701e-05 - val_loss: 1.6951e-04\n",
      "Epoch 119/1000\n",
      "871/871 [==============================] - 0s 135us/step - loss: 7.7639e-05 - val_loss: 1.8264e-04\n",
      "Epoch 120/1000\n",
      "871/871 [==============================] - 0s 120us/step - loss: 7.7201e-05 - val_loss: 1.7782e-04\n",
      "Epoch 121/1000\n",
      "871/871 [==============================] - 0s 102us/step - loss: 7.6928e-05 - val_loss: 1.8205e-04\n",
      "Epoch 122/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 7.6495e-05 - val_loss: 1.9044e-04\n",
      "Epoch 123/1000\n",
      "871/871 [==============================] - 0s 112us/step - loss: 7.6445e-05 - val_loss: 1.7281e-04\n",
      "Epoch 124/1000\n",
      "871/871 [==============================] - 0s 87us/step - loss: 7.6331e-05 - val_loss: 1.7232e-04\n",
      "Epoch 125/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 7.5929e-05 - val_loss: 1.8859e-04\n",
      "Epoch 126/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 7.5320e-05 - val_loss: 1.6062e-04\n",
      "Epoch 127/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 7.5926e-05 - val_loss: 1.7883e-04\n",
      "Epoch 128/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 7.5281e-05 - val_loss: 1.8969e-04\n",
      "Epoch 129/1000\n",
      "871/871 [==============================] - 0s 109us/step - loss: 7.4647e-05 - val_loss: 1.6786e-04\n",
      "Epoch 130/1000\n",
      "871/871 [==============================] - ETA: 0s - loss: 7.6478e-0 - 0s 108us/step - loss: 7.4661e-05 - val_loss: 1.7335e-04\n",
      "Epoch 131/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 7.3958e-05 - val_loss: 1.8766e-04\n",
      "Epoch 132/1000\n",
      "871/871 [==============================] - 0s 128us/step - loss: 7.3984e-05 - val_loss: 1.6786e-04\n",
      "Epoch 133/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 7.4394e-05 - val_loss: 1.6988e-04\n",
      "Epoch 134/1000\n",
      "871/871 [==============================] - 0s 106us/step - loss: 7.3867e-05 - val_loss: 1.8864e-04\n",
      "Epoch 135/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 7.3064e-05 - val_loss: 1.6377e-04\n",
      "Epoch 136/1000\n",
      "871/871 [==============================] - 0s 102us/step - loss: 7.2836e-05 - val_loss: 1.6840e-04\n",
      "Epoch 137/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871/871 [==============================] - 0s 99us/step - loss: 7.2351e-05 - val_loss: 1.8245e-04\n",
      "Epoch 138/1000\n",
      "871/871 [==============================] - 0s 125us/step - loss: 7.2122e-05 - val_loss: 1.6311e-04\n",
      "Epoch 139/1000\n",
      "871/871 [==============================] - 0s 105us/step - loss: 7.2077e-05 - val_loss: 1.8003e-04\n",
      "Epoch 140/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 7.1692e-05 - val_loss: 1.8096e-04\n",
      "Epoch 141/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 7.1492e-05 - val_loss: 1.6371e-04\n",
      "Epoch 142/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 7.1589e-05 - val_loss: 1.6922e-04\n",
      "Epoch 143/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 7.1616e-05 - val_loss: 1.7341e-04\n",
      "Epoch 144/1000\n",
      "871/871 [==============================] - 0s 119us/step - loss: 7.0772e-05 - val_loss: 1.5830e-04\n",
      "Epoch 145/1000\n",
      "871/871 [==============================] - 0s 113us/step - loss: 7.0373e-05 - val_loss: 1.7896e-04\n",
      "Epoch 146/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 7.0537e-05 - val_loss: 1.6289e-04\n",
      "Epoch 147/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.9709e-05 - val_loss: 1.7236e-04\n",
      "Epoch 148/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.9954e-05 - val_loss: 1.6236e-04\n",
      "Epoch 149/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 6.9776e-05 - val_loss: 1.7533e-04\n",
      "Epoch 150/1000\n",
      "871/871 [==============================] - 0s 110us/step - loss: 6.8283e-05 - val_loss: 1.4530e-04\n",
      "Epoch 151/1000\n",
      "871/871 [==============================] - 0s 107us/step - loss: 6.8962e-05 - val_loss: 1.7791e-04\n",
      "Epoch 152/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.8399e-05 - val_loss: 1.6361e-04\n",
      "Epoch 153/1000\n",
      "871/871 [==============================] - 0s 106us/step - loss: 6.8183e-05 - val_loss: 1.6503e-04\n",
      "Epoch 154/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.8397e-05 - val_loss: 1.6696e-04\n",
      "Epoch 155/1000\n",
      "871/871 [==============================] - 0s 122us/step - loss: 6.8098e-05 - val_loss: 1.5716e-04\n",
      "Epoch 156/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.7538e-05 - val_loss: 1.7453e-04\n",
      "Epoch 157/1000\n",
      "871/871 [==============================] - 0s 104us/step - loss: 6.7019e-05 - val_loss: 1.5189e-04\n",
      "Epoch 158/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.6314e-05 - val_loss: 1.7916e-04\n",
      "Epoch 159/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.7338e-05 - val_loss: 1.5335e-04\n",
      "Epoch 160/1000\n",
      "871/871 [==============================] - 0s 117us/step - loss: 6.6275e-05 - val_loss: 1.6644e-04\n",
      "Epoch 161/1000\n",
      "871/871 [==============================] - 0s 103us/step - loss: 6.5822e-05 - val_loss: 1.6584e-04\n",
      "Epoch 162/1000\n",
      "871/871 [==============================] - 0s 93us/step - loss: 6.5456e-05 - val_loss: 1.5969e-04\n",
      "Epoch 163/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 6.5100e-05 - val_loss: 1.5845e-04\n",
      "Epoch 164/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.4750e-05 - val_loss: 1.6321e-04\n",
      "Epoch 165/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.5033e-05 - val_loss: 1.4892e-04\n",
      "Epoch 166/1000\n",
      "871/871 [==============================] - 0s 136us/step - loss: 6.5796e-05 - val_loss: 1.6155e-04\n",
      "Epoch 167/1000\n",
      "871/871 [==============================] - 0s 94us/step - loss: 6.5521e-05 - val_loss: 1.5443e-04\n",
      "Epoch 168/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.5470e-05 - val_loss: 1.5309e-04\n",
      "Epoch 169/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.6724e-05 - val_loss: 1.5699e-04\n",
      "Epoch 170/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 6.4668e-05 - val_loss: 1.3769e-04\n",
      "Epoch 171/1000\n",
      "871/871 [==============================] - 0s 122us/step - loss: 6.3838e-05 - val_loss: 1.7108e-04\n",
      "Epoch 172/1000\n",
      "871/871 [==============================] - 0s 91us/step - loss: 6.3401e-05 - val_loss: 1.4316e-04\n",
      "Epoch 173/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.2997e-05 - val_loss: 1.5343e-04\n",
      "Epoch 174/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.2785e-05 - val_loss: 1.4748e-04\n",
      "Epoch 175/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 6.2712e-05 - val_loss: 1.6303e-04\n",
      "Epoch 176/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.1682e-05 - val_loss: 1.4064e-04\n",
      "Epoch 177/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 6.1481e-05 - val_loss: 1.5341e-04\n",
      "Epoch 178/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.1089e-05 - val_loss: 1.4925e-04\n",
      "Epoch 179/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.0735e-05 - val_loss: 1.4240e-04\n",
      "Epoch 180/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.0595e-05 - val_loss: 1.6305e-04\n",
      "Epoch 181/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.1577e-05 - val_loss: 1.3161e-04\n",
      "Epoch 182/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.0741e-05 - val_loss: 1.5298e-04\n",
      "Epoch 183/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.0343e-05 - val_loss: 1.4705e-04\n",
      "Epoch 184/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 6.0068e-05 - val_loss: 1.4812e-04\n",
      "Epoch 185/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.9086e-05 - val_loss: 1.5184e-04\n",
      "Epoch 186/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.9585e-05 - val_loss: 1.5149e-04\n",
      "Epoch 187/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.9364e-05 - val_loss: 1.4630e-04\n",
      "Epoch 188/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.8890e-05 - val_loss: 1.4014e-04\n",
      "Epoch 189/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.8066e-05 - val_loss: 1.5894e-04\n",
      "Epoch 190/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.8282e-05 - val_loss: 1.3516e-04\n",
      "Epoch 191/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.8046e-05 - val_loss: 1.4275e-04\n",
      "Epoch 192/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.7920e-05 - val_loss: 1.4805e-04\n",
      "Epoch 193/1000\n",
      "871/871 [==============================] - 0s 106us/step - loss: 5.7357e-05 - val_loss: 1.3808e-04\n",
      "Epoch 194/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.7370e-05 - val_loss: 1.4779e-04\n",
      "Epoch 195/1000\n",
      "871/871 [==============================] - 0s 119us/step - loss: 5.7610e-05 - val_loss: 1.3494e-04\n",
      "Epoch 196/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 5.7047e-05 - val_loss: 1.4200e-04\n",
      "Epoch 197/1000\n",
      "871/871 [==============================] - 0s 112us/step - loss: 5.6842e-05 - val_loss: 1.4247e-04\n",
      "Epoch 198/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 5.6166e-05 - val_loss: 1.3251e-04\n",
      "Epoch 199/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.5718e-05 - val_loss: 1.4496e-04\n",
      "Epoch 200/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.5205e-05 - val_loss: 1.4293e-04\n",
      "Epoch 201/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.4909e-05 - val_loss: 1.3209e-04\n",
      "Epoch 202/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.4548e-05 - val_loss: 1.4692e-04\n",
      "Epoch 203/1000\n",
      "871/871 [==============================] - 0s 106us/step - loss: 5.4590e-05 - val_loss: 1.3153e-04\n",
      "Epoch 204/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.4191e-05 - val_loss: 1.4184e-04\n",
      "Epoch 205/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.3852e-05 - val_loss: 1.4012e-04\n",
      "Epoch 206/1000\n",
      "871/871 [==============================] - 0s 93us/step - loss: 5.3921e-05 - val_loss: 1.1600e-04\n",
      "Epoch 207/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.4416e-05 - val_loss: 1.4514e-04\n",
      "Epoch 208/1000\n",
      "871/871 [==============================] - 0s 118us/step - loss: 5.3512e-05 - val_loss: 1.2000e-04\n",
      "Epoch 209/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871/871 [==============================] - 0s 95us/step - loss: 5.3548e-05 - val_loss: 1.4270e-04\n",
      "Epoch 210/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.3528e-05 - val_loss: 1.2244e-04\n",
      "Epoch 211/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.2560e-05 - val_loss: 1.4666e-04\n",
      "Epoch 212/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.2436e-05 - val_loss: 1.2090e-04\n",
      "Epoch 213/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.3110e-05 - val_loss: 1.4367e-04\n",
      "Epoch 214/1000\n",
      "871/871 [==============================] - 0s 91us/step - loss: 5.1940e-05 - val_loss: 1.2319e-04\n",
      "Epoch 215/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.1288e-05 - val_loss: 1.3660e-04\n",
      "Epoch 216/1000\n",
      "871/871 [==============================] - 0s 123us/step - loss: 5.0948e-05 - val_loss: 1.2362e-04\n",
      "Epoch 217/1000\n",
      "871/871 [==============================] - 0s 92us/step - loss: 5.0716e-05 - val_loss: 1.4437e-04\n",
      "Epoch 218/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.1487e-05 - val_loss: 1.0999e-04\n",
      "Epoch 219/1000\n",
      "871/871 [==============================] - 0s 117us/step - loss: 5.3136e-05 - val_loss: 1.5462e-04\n",
      "Epoch 220/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.4618e-05 - val_loss: 1.1431e-04\n",
      "Epoch 221/1000\n",
      "871/871 [==============================] - 0s 110us/step - loss: 5.0113e-05 - val_loss: 1.3563e-04\n",
      "Epoch 222/1000\n",
      "871/871 [==============================] - 0s 109us/step - loss: 4.9803e-05 - val_loss: 1.1971e-04\n",
      "Epoch 223/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.9316e-05 - val_loss: 1.2663e-04\n",
      "Epoch 224/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.8973e-05 - val_loss: 1.3255e-04\n",
      "Epoch 225/1000\n",
      "871/871 [==============================] - 0s 102us/step - loss: 4.9323e-05 - val_loss: 1.0769e-04\n",
      "Epoch 226/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.0206e-05 - val_loss: 1.4376e-04\n",
      "Epoch 227/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 5.0097e-05 - val_loss: 1.0575e-04\n",
      "Epoch 228/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.9724e-05 - val_loss: 1.4672e-04\n",
      "Epoch 229/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.9917e-05 - val_loss: 1.0573e-04\n",
      "Epoch 230/1000\n",
      "871/871 [==============================] - 0s 121us/step - loss: 4.7959e-05 - val_loss: 1.3393e-04\n",
      "Epoch 231/1000\n",
      "871/871 [==============================] - 0s 117us/step - loss: 4.7464e-05 - val_loss: 1.1285e-04\n",
      "Epoch 232/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 4.7067e-05 - val_loss: 1.4383e-04\n",
      "Epoch 233/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.8687e-05 - val_loss: 1.1274e-04\n",
      "Epoch 234/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.6737e-05 - val_loss: 1.2110e-04\n",
      "Epoch 235/1000\n",
      "871/871 [==============================] - 0s 118us/step - loss: 4.6148e-05 - val_loss: 1.1098e-04\n",
      "Epoch 236/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.6249e-05 - val_loss: 1.2658e-04\n",
      "Epoch 237/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.6087e-05 - val_loss: 1.1457e-04\n",
      "Epoch 238/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.5359e-05 - val_loss: 1.3121e-04\n",
      "Epoch 239/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.5535e-05 - val_loss: 1.1104e-04\n",
      "Epoch 240/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.5182e-05 - val_loss: 1.1521e-04\n",
      "Epoch 241/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.4942e-05 - val_loss: 1.0993e-04\n",
      "Epoch 242/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.4577e-05 - val_loss: 1.2150e-04\n",
      "Epoch 243/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.4437e-05 - val_loss: 1.1429e-04\n",
      "Epoch 244/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.4099e-05 - val_loss: 1.1834e-04\n",
      "Epoch 245/1000\n",
      "871/871 [==============================] - 0s 99us/step - loss: 4.3898e-05 - val_loss: 1.1174e-04\n",
      "Epoch 246/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.3742e-05 - val_loss: 1.1828e-04\n",
      "Epoch 247/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.3473e-05 - val_loss: 1.1930e-04\n",
      "Epoch 248/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.3427e-05 - val_loss: 1.1007e-04\n",
      "Epoch 249/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.2777e-05 - val_loss: 1.2181e-04\n",
      "Epoch 250/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.3457e-05 - val_loss: 1.0063e-04\n",
      "Epoch 251/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.2459e-05 - val_loss: 1.1750e-04\n",
      "Epoch 252/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.2264e-05 - val_loss: 1.0350e-04\n",
      "Epoch 253/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.2318e-05 - val_loss: 1.1758e-04\n",
      "Epoch 254/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.1657e-05 - val_loss: 9.5392e-05\n",
      "Epoch 255/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 4.2136e-05 - val_loss: 1.1033e-04\n",
      "Epoch 256/1000\n",
      "871/871 [==============================] - 0s 121us/step - loss: 4.1382e-05 - val_loss: 1.0426e-04\n",
      "Epoch 257/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 4.1365e-05 - val_loss: 1.0267e-04\n",
      "Epoch 258/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.0826e-05 - val_loss: 1.0660e-04\n",
      "Epoch 259/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.0592e-05 - val_loss: 1.0171e-04\n",
      "Epoch 260/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 4.0391e-05 - val_loss: 1.0116e-04\n",
      "Epoch 261/1000\n",
      "871/871 [==============================] - 0s 100us/step - loss: 4.0358e-05 - val_loss: 1.1393e-04\n",
      "Epoch 262/1000\n",
      "871/871 [==============================] - 0s 119us/step - loss: 4.0046e-05 - val_loss: 8.4999e-05\n",
      "Epoch 263/1000\n",
      "871/871 [==============================] - 0s 107us/step - loss: 4.0815e-05 - val_loss: 1.1046e-04\n",
      "Epoch 264/1000\n",
      "871/871 [==============================] - 0s 110us/step - loss: 3.9632e-05 - val_loss: 1.0141e-04\n",
      "Epoch 265/1000\n",
      "871/871 [==============================] - 0s 103us/step - loss: 3.9276e-05 - val_loss: 1.0615e-04\n",
      "Epoch 266/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 3.8959e-05 - val_loss: 1.0106e-04\n",
      "Epoch 267/1000\n",
      "871/871 [==============================] - 0s 117us/step - loss: 3.8816e-05 - val_loss: 1.1162e-04\n",
      "Epoch 268/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.9276e-05 - val_loss: 8.7490e-05\n",
      "Epoch 269/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.8793e-05 - val_loss: 1.0288e-04\n",
      "Epoch 270/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.8022e-05 - val_loss: 8.9705e-05\n",
      "Epoch 271/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.8459e-05 - val_loss: 1.0019e-04\n",
      "Epoch 272/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.7714e-05 - val_loss: 9.4226e-05\n",
      "Epoch 273/1000\n",
      "871/871 [==============================] - 0s 118us/step - loss: 3.8114e-05 - val_loss: 1.1334e-04\n",
      "Epoch 274/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 3.7764e-05 - val_loss: 8.6366e-05\n",
      "Epoch 275/1000\n",
      "871/871 [==============================] - 0s 125us/step - loss: 3.7578e-05 - val_loss: 9.4474e-05\n",
      "Epoch 276/1000\n",
      "871/871 [==============================] - 0s 110us/step - loss: 3.7267e-05 - val_loss: 9.8744e-05\n",
      "Epoch 277/1000\n",
      "871/871 [==============================] - 0s 110us/step - loss: 3.6786e-05 - val_loss: 1.0677e-04\n",
      "Epoch 278/1000\n",
      "871/871 [==============================] - 0s 82us/step - loss: 3.7620e-05 - val_loss: 7.5023e-05\n",
      "Epoch 279/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 3.7674e-05 - val_loss: 1.1366e-04\n",
      "Epoch 280/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.7073e-05 - val_loss: 8.7520e-05\n",
      "Epoch 281/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871/871 [==============================] - 0s 109us/step - loss: 3.5737e-05 - val_loss: 9.4041e-05\n",
      "Epoch 282/1000\n",
      "871/871 [==============================] - 0s 110us/step - loss: 3.5642e-05 - val_loss: 9.4113e-05\n",
      "Epoch 283/1000\n",
      "871/871 [==============================] - 0s 102us/step - loss: 3.5448e-05 - val_loss: 8.3290e-05\n",
      "Epoch 284/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.5443e-05 - val_loss: 1.0069e-04\n",
      "Epoch 285/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 3.5177e-05 - val_loss: 8.4915e-05\n",
      "Epoch 286/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.4896e-05 - val_loss: 8.0696e-05\n",
      "Epoch 287/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 3.5569e-05 - val_loss: 1.1017e-04\n",
      "Epoch 288/1000\n",
      "871/871 [==============================] - 0s 114us/step - loss: 3.5608e-05 - val_loss: 7.6384e-05\n",
      "Epoch 289/1000\n",
      "871/871 [==============================] - 0s 98us/step - loss: 3.4433e-05 - val_loss: 9.3559e-05\n",
      "Epoch 290/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 3.4161e-05 - val_loss: 9.9781e-05\n",
      "Epoch 291/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.4640e-05 - val_loss: 8.0299e-05\n",
      "Epoch 292/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.3913e-05 - val_loss: 7.8990e-05\n",
      "Epoch 293/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 3.3414e-05 - val_loss: 9.8185e-05\n",
      "Epoch 294/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.3547e-05 - val_loss: 6.6600e-05\n",
      "Epoch 295/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.4452e-05 - val_loss: 9.8640e-05\n",
      "Epoch 296/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 3.2881e-05 - val_loss: 8.4525e-05\n",
      "Epoch 297/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.3079e-05 - val_loss: 8.1358e-05\n",
      "Epoch 298/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.2249e-05 - val_loss: 8.5339e-05\n",
      "Epoch 299/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 3.2010e-05 - val_loss: 8.0562e-05\n",
      "Epoch 300/1000\n",
      "871/871 [==============================] - 0s 113us/step - loss: 3.1887e-05 - val_loss: 9.0896e-05\n",
      "Epoch 301/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 3.1992e-05 - val_loss: 7.8978e-05\n",
      "Epoch 302/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.1893e-05 - val_loss: 6.7782e-05\n",
      "Epoch 303/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.2122e-05 - val_loss: 9.7242e-05\n",
      "Epoch 304/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 3.1573e-05 - val_loss: 6.3806e-05\n",
      "Epoch 305/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.1156e-05 - val_loss: 9.4153e-05\n",
      "Epoch 306/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.0893e-05 - val_loss: 6.6883e-05\n",
      "Epoch 307/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.1121e-05 - val_loss: 7.8015e-05\n",
      "Epoch 308/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 3.0797e-05 - val_loss: 9.4814e-05\n",
      "Epoch 309/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 3.1582e-05 - val_loss: 5.4261e-05\n",
      "Epoch 310/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.1922e-05 - val_loss: 8.8656e-05\n",
      "Epoch 311/1000\n",
      "871/871 [==============================] - 0s 100us/step - loss: 3.0676e-05 - val_loss: 7.7763e-05\n",
      "Epoch 312/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 3.0327e-05 - val_loss: 6.0786e-05\n",
      "Epoch 313/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.0497e-05 - val_loss: 9.6798e-05\n",
      "Epoch 314/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.0743e-05 - val_loss: 7.5713e-05\n",
      "Epoch 315/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 3.0251e-05 - val_loss: 5.7896e-05\n",
      "Epoch 316/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.9917e-05 - val_loss: 8.2591e-05\n",
      "Epoch 317/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.9092e-05 - val_loss: 7.7715e-05\n",
      "Epoch 318/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.8926e-05 - val_loss: 7.0791e-05\n",
      "Epoch 319/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.8754e-05 - val_loss: 6.1140e-05\n",
      "Epoch 320/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.8607e-05 - val_loss: 7.5320e-05\n",
      "Epoch 321/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.8053e-05 - val_loss: 7.2845e-05\n",
      "Epoch 322/1000\n",
      "871/871 [==============================] - 0s 93us/step - loss: 2.8055e-05 - val_loss: 6.7402e-05\n",
      "Epoch 323/1000\n",
      "871/871 [==============================] - 0s 106us/step - loss: 2.7648e-05 - val_loss: 6.8608e-05\n",
      "Epoch 324/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.7473e-05 - val_loss: 6.6164e-05\n",
      "Epoch 325/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.7291e-05 - val_loss: 6.9566e-05\n",
      "Epoch 326/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.7126e-05 - val_loss: 6.8212e-05\n",
      "Epoch 327/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.7452e-05 - val_loss: 7.4278e-05\n",
      "Epoch 328/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.7785e-05 - val_loss: 7.4883e-05\n",
      "Epoch 329/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.7297e-05 - val_loss: 7.3087e-05\n",
      "Epoch 330/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.6719e-05 - val_loss: 7.1584e-05\n",
      "Epoch 331/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.6396e-05 - val_loss: 5.7717e-05\n",
      "Epoch 332/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.6771e-05 - val_loss: 7.3874e-05\n",
      "Epoch 333/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 2.7056e-05 - val_loss: 7.9784e-05\n",
      "Epoch 334/1000\n",
      "871/871 [==============================] - 0s 94us/step - loss: 2.6547e-05 - val_loss: 4.9011e-05\n",
      "Epoch 335/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.6663e-05 - val_loss: 7.0992e-05\n",
      "Epoch 336/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.5832e-05 - val_loss: 5.9375e-05\n",
      "Epoch 337/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.5722e-05 - val_loss: 6.5148e-05\n",
      "Epoch 338/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.5568e-05 - val_loss: 7.2226e-05\n",
      "Epoch 339/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.5381e-05 - val_loss: 4.3822e-05\n",
      "Epoch 340/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.6828e-05 - val_loss: 7.4021e-05\n",
      "Epoch 341/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.4988e-05 - val_loss: 5.5978e-05\n",
      "Epoch 342/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.4978e-05 - val_loss: 5.3363e-05\n",
      "Epoch 343/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.4778e-05 - val_loss: 6.5874e-05\n",
      "Epoch 344/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.4615e-05 - val_loss: 6.9080e-05\n",
      "Epoch 345/1000\n",
      "871/871 [==============================] - 0s 114us/step - loss: 2.4839e-05 - val_loss: 4.9543e-05\n",
      "Epoch 346/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.4278e-05 - val_loss: 6.3590e-05\n",
      "Epoch 347/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.3842e-05 - val_loss: 4.7287e-05\n",
      "Epoch 348/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.4348e-05 - val_loss: 7.0814e-05\n",
      "Epoch 349/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.3987e-05 - val_loss: 5.4903e-05\n",
      "Epoch 350/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.3882e-05 - val_loss: 4.9070e-05\n",
      "Epoch 351/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.3999e-05 - val_loss: 6.6872e-05\n",
      "Epoch 352/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.3975e-05 - val_loss: 5.8400e-05\n",
      "Epoch 353/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.3366e-05 - val_loss: 5.2926e-05\n",
      "Epoch 354/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.3183e-05 - val_loss: 4.7379e-05\n",
      "Epoch 355/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.4030e-05 - val_loss: 6.4715e-05\n",
      "Epoch 356/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.3237e-05 - val_loss: 5.2225e-05\n",
      "Epoch 357/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.2813e-05 - val_loss: 4.8759e-05\n",
      "Epoch 358/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.2889e-05 - val_loss: 4.8171e-05\n",
      "Epoch 359/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 2.2970e-05 - val_loss: 7.1093e-05\n",
      "Epoch 360/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.3586e-05 - val_loss: 5.1359e-05\n",
      "Epoch 361/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.2725e-05 - val_loss: 4.0582e-05\n",
      "Epoch 362/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.3070e-05 - val_loss: 5.4282e-05\n",
      "Epoch 363/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.2116e-05 - val_loss: 6.2985e-05\n",
      "Epoch 364/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.2709e-05 - val_loss: 3.7356e-05\n",
      "Epoch 365/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.3242e-05 - val_loss: 4.4228e-05\n",
      "Epoch 366/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.3054e-05 - val_loss: 6.9790e-05\n",
      "Epoch 367/1000\n",
      "871/871 [==============================] - 0s 114us/step - loss: 2.2224e-05 - val_loss: 4.0965e-05\n",
      "Epoch 368/1000\n",
      "871/871 [==============================] - 0s 94us/step - loss: 2.1864e-05 - val_loss: 5.2372e-05\n",
      "Epoch 369/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.1282e-05 - val_loss: 5.3618e-05\n",
      "Epoch 370/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.1356e-05 - val_loss: 4.2739e-05\n",
      "Epoch 371/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.1296e-05 - val_loss: 3.9900e-05\n",
      "Epoch 372/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.1580e-05 - val_loss: 6.9914e-05\n",
      "Epoch 373/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.2579e-05 - val_loss: 5.0136e-05\n",
      "Epoch 374/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.2252e-05 - val_loss: 3.0072e-05\n",
      "Epoch 375/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.2126e-05 - val_loss: 5.7117e-05\n",
      "Epoch 376/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.1551e-05 - val_loss: 5.5989e-05\n",
      "Epoch 377/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.0980e-05 - val_loss: 5.2629e-05\n",
      "Epoch 378/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 2.0838e-05 - val_loss: 3.6735e-05\n",
      "Epoch 379/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 2.0857e-05 - val_loss: 4.2883e-05\n",
      "Epoch 380/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.1132e-05 - val_loss: 5.0621e-05\n",
      "Epoch 381/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.0163e-05 - val_loss: 4.6461e-05\n",
      "Epoch 382/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.0231e-05 - val_loss: 3.7204e-05\n",
      "Epoch 383/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.0989e-05 - val_loss: 3.4748e-05\n",
      "Epoch 384/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.0986e-05 - val_loss: 3.9542e-05\n",
      "Epoch 385/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.9767e-05 - val_loss: 5.3719e-05\n",
      "Epoch 386/1000\n",
      "871/871 [==============================] - 0s 143us/step - loss: 2.0062e-05 - val_loss: 4.7652e-05\n",
      "Epoch 387/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.9597e-05 - val_loss: 3.7891e-05\n",
      "Epoch 388/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.9513e-05 - val_loss: 4.4669e-05\n",
      "Epoch 389/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.9359e-05 - val_loss: 5.4850e-05\n",
      "Epoch 390/1000\n",
      "871/871 [==============================] - 0s 109us/step - loss: 2.0279e-05 - val_loss: 2.8037e-05\n",
      "Epoch 391/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.0580e-05 - val_loss: 3.5169e-05\n",
      "Epoch 392/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.9665e-05 - val_loss: 6.5128e-05\n",
      "Epoch 393/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 2.1553e-05 - val_loss: 4.0566e-05\n",
      "Epoch 394/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.9888e-05 - val_loss: 2.8720e-05\n",
      "Epoch 395/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.9992e-05 - val_loss: 3.6797e-05\n",
      "Epoch 396/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.9274e-05 - val_loss: 4.2931e-05\n",
      "Epoch 397/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.9197e-05 - val_loss: 4.9816e-05\n",
      "Epoch 398/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.9555e-05 - val_loss: 4.1952e-05\n",
      "Epoch 399/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8602e-05 - val_loss: 4.2592e-05\n",
      "Epoch 400/1000\n",
      "871/871 [==============================] - 0s 131us/step - loss: 1.8702e-05 - val_loss: 5.0220e-05\n",
      "Epoch 401/1000\n",
      "871/871 [==============================] - 0s 96us/step - loss: 1.8944e-05 - val_loss: 3.6397e-05\n",
      "Epoch 402/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.8913e-05 - val_loss: 3.8771e-05\n",
      "Epoch 403/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8305e-05 - val_loss: 3.1677e-05\n",
      "Epoch 404/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8317e-05 - val_loss: 3.8013e-05\n",
      "Epoch 405/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.8539e-05 - val_loss: 3.8740e-05\n",
      "Epoch 406/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8124e-05 - val_loss: 4.2525e-05\n",
      "Epoch 407/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.8326e-05 - val_loss: 3.8715e-05\n",
      "Epoch 408/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8277e-05 - val_loss: 2.5340e-05\n",
      "Epoch 409/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8922e-05 - val_loss: 3.7282e-05\n",
      "Epoch 410/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.8688e-05 - val_loss: 4.9054e-05\n",
      "Epoch 411/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8758e-05 - val_loss: 3.8798e-05\n",
      "Epoch 412/1000\n",
      "871/871 [==============================] - 0s 99us/step - loss: 1.7760e-05 - val_loss: 3.1317e-05\n",
      "Epoch 413/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.7638e-05 - val_loss: 3.3614e-05\n",
      "Epoch 414/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7516e-05 - val_loss: 3.4781e-05\n",
      "Epoch 415/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7905e-05 - val_loss: 3.6817e-05\n",
      "Epoch 416/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8029e-05 - val_loss: 4.8920e-05\n",
      "Epoch 417/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8705e-05 - val_loss: 4.0043e-05\n",
      "Epoch 418/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7402e-05 - val_loss: 3.1912e-05\n",
      "Epoch 419/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.7487e-05 - val_loss: 2.6118e-05\n",
      "Epoch 420/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8229e-05 - val_loss: 2.7820e-05\n",
      "Epoch 421/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8581e-05 - val_loss: 4.1598e-05\n",
      "Epoch 422/1000\n",
      "871/871 [==============================] - 0s 122us/step - loss: 1.9000e-05 - val_loss: 4.5203e-05\n",
      "Epoch 423/1000\n",
      "871/871 [==============================] - 0s 113us/step - loss: 1.8454e-05 - val_loss: 4.0035e-05\n",
      "Epoch 424/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7486e-05 - val_loss: 3.1678e-05\n",
      "Epoch 425/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871/871 [==============================] - 0s 108us/step - loss: 1.6979e-05 - val_loss: 3.9388e-05\n",
      "Epoch 426/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7044e-05 - val_loss: 3.7099e-05\n",
      "Epoch 427/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7307e-05 - val_loss: 3.6030e-05\n",
      "Epoch 428/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7566e-05 - val_loss: 2.7008e-05\n",
      "Epoch 429/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6800e-05 - val_loss: 3.1657e-05\n",
      "Epoch 430/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.6590e-05 - val_loss: 3.1003e-05\n",
      "Epoch 431/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.6572e-05 - val_loss: 3.3401e-05\n",
      "Epoch 432/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.6517e-05 - val_loss: 3.7739e-05\n",
      "Epoch 433/1000\n",
      "871/871 [==============================] - 0s 109us/step - loss: 1.7188e-05 - val_loss: 3.4016e-05\n",
      "Epoch 434/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7519e-05 - val_loss: 2.8489e-05\n",
      "Epoch 435/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.6719e-05 - val_loss: 2.3854e-05\n",
      "Epoch 436/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6620e-05 - val_loss: 2.7481e-05\n",
      "Epoch 437/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6495e-05 - val_loss: 2.7416e-05\n",
      "Epoch 438/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6214e-05 - val_loss: 2.9198e-05\n",
      "Epoch 439/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6108e-05 - val_loss: 2.5459e-05\n",
      "Epoch 440/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6204e-05 - val_loss: 2.6539e-05\n",
      "Epoch 441/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6269e-05 - val_loss: 2.9566e-05\n",
      "Epoch 442/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6311e-05 - val_loss: 4.1016e-05\n",
      "Epoch 443/1000\n",
      "871/871 [==============================] - 0s 118us/step - loss: 1.6710e-05 - val_loss: 3.2148e-05\n",
      "Epoch 444/1000\n",
      "871/871 [==============================] - 0s 99us/step - loss: 1.7782e-05 - val_loss: 2.1373e-05\n",
      "Epoch 445/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7401e-05 - val_loss: 1.9193e-05\n",
      "Epoch 446/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7132e-05 - val_loss: 2.8394e-05\n",
      "Epoch 447/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6480e-05 - val_loss: 3.5891e-05\n",
      "Epoch 448/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6500e-05 - val_loss: 3.8325e-05\n",
      "Epoch 449/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7017e-05 - val_loss: 4.2087e-05\n",
      "Epoch 450/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.8238e-05 - val_loss: 3.3153e-05\n",
      "Epoch 451/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.7114e-05 - val_loss: 2.0637e-05\n",
      "Epoch 452/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7033e-05 - val_loss: 2.4018e-05\n",
      "Epoch 453/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5755e-05 - val_loss: 2.6709e-05\n",
      "Epoch 454/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5612e-05 - val_loss: 2.1014e-05\n",
      "Epoch 455/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6111e-05 - val_loss: 2.6593e-05\n",
      "Epoch 456/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5874e-05 - val_loss: 2.8527e-05\n",
      "Epoch 457/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5825e-05 - val_loss: 3.8479e-05\n",
      "Epoch 458/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5957e-05 - val_loss: 2.5997e-05\n",
      "Epoch 459/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.5358e-05 - val_loss: 3.3861e-05\n",
      "Epoch 460/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5868e-05 - val_loss: 2.7206e-05\n",
      "Epoch 461/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.5400e-05 - val_loss: 2.9266e-05\n",
      "Epoch 462/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5301e-05 - val_loss: 2.3539e-05\n",
      "Epoch 463/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.5752e-05 - val_loss: 2.3244e-05\n",
      "Epoch 464/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5565e-05 - val_loss: 2.2534e-05\n",
      "Epoch 465/1000\n",
      "871/871 [==============================] - 0s 109us/step - loss: 1.5232e-05 - val_loss: 2.7055e-05\n",
      "Epoch 466/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5228e-05 - val_loss: 2.6660e-05\n",
      "Epoch 467/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5273e-05 - val_loss: 2.7564e-05\n",
      "Epoch 468/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5257e-05 - val_loss: 2.5201e-05\n",
      "Epoch 469/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5132e-05 - val_loss: 2.6350e-05\n",
      "Epoch 470/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5047e-05 - val_loss: 2.5731e-05\n",
      "Epoch 471/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5365e-05 - val_loss: 2.3990e-05\n",
      "Epoch 472/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5470e-05 - val_loss: 2.6245e-05\n",
      "Epoch 473/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.5457e-05 - val_loss: 2.6036e-05\n",
      "Epoch 474/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5542e-05 - val_loss: 2.3032e-05\n",
      "Epoch 475/1000\n",
      "871/871 [==============================] - 0s 109us/step - loss: 1.5086e-05 - val_loss: 3.2191e-05\n",
      "Epoch 476/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5812e-05 - val_loss: 3.6754e-05\n",
      "Epoch 477/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7798e-05 - val_loss: 3.1978e-05\n",
      "Epoch 478/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7072e-05 - val_loss: 2.6518e-05\n",
      "Epoch 479/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6406e-05 - val_loss: 2.0415e-05\n",
      "Epoch 480/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5785e-05 - val_loss: 1.8316e-05\n",
      "Epoch 481/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5966e-05 - val_loss: 1.5464e-05\n",
      "Epoch 482/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7264e-05 - val_loss: 1.8571e-05\n",
      "Epoch 483/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7273e-05 - val_loss: 1.9765e-05\n",
      "Epoch 484/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6752e-05 - val_loss: 2.5170e-05\n",
      "Epoch 485/1000\n",
      "871/871 [==============================] - 0s 120us/step - loss: 1.5526e-05 - val_loss: 3.3941e-05\n",
      "Epoch 486/1000\n",
      "871/871 [==============================] - 0s 99us/step - loss: 1.6329e-05 - val_loss: 3.3738e-05\n",
      "Epoch 487/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5713e-05 - val_loss: 2.9402e-05\n",
      "Epoch 488/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5105e-05 - val_loss: 2.0437e-05\n",
      "Epoch 489/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4592e-05 - val_loss: 2.7820e-05\n",
      "Epoch 490/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5140e-05 - val_loss: 3.3492e-05\n",
      "Epoch 491/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5261e-05 - val_loss: 2.1112e-05\n",
      "Epoch 492/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4595e-05 - val_loss: 1.8256e-05\n",
      "Epoch 493/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5173e-05 - val_loss: 2.0962e-05\n",
      "Epoch 494/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5388e-05 - val_loss: 1.9462e-05\n",
      "Epoch 495/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5635e-05 - val_loss: 2.0744e-05\n",
      "Epoch 496/1000\n",
      "871/871 [==============================] - 0s 122us/step - loss: 1.5860e-05 - val_loss: 1.6101e-05\n",
      "Epoch 497/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871/871 [==============================] - 0s 108us/step - loss: 1.7484e-05 - val_loss: 2.0665e-05\n",
      "Epoch 498/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5435e-05 - val_loss: 2.8036e-05\n",
      "Epoch 499/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4823e-05 - val_loss: 2.2005e-05\n",
      "Epoch 500/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.4620e-05 - val_loss: 1.9328e-05\n",
      "Epoch 501/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.4543e-05 - val_loss: 1.7949e-05\n",
      "Epoch 502/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.5069e-05 - val_loss: 1.7533e-05\n",
      "Epoch 503/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4461e-05 - val_loss: 1.9001e-05\n",
      "Epoch 504/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4708e-05 - val_loss: 2.0200e-05\n",
      "Epoch 505/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4608e-05 - val_loss: 1.7015e-05\n",
      "Epoch 506/1000\n",
      "871/871 [==============================] - 0s 106us/step - loss: 1.5116e-05 - val_loss: 2.2546e-05\n",
      "Epoch 507/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.4809e-05 - val_loss: 1.8967e-05\n",
      "Epoch 508/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6434e-05 - val_loss: 1.6816e-05\n",
      "Epoch 509/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7071e-05 - val_loss: 1.9714e-05\n",
      "Epoch 510/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5829e-05 - val_loss: 1.6160e-05\n",
      "Epoch 511/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5939e-05 - val_loss: 1.6809e-05\n",
      "Epoch 512/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6378e-05 - val_loss: 1.9580e-05\n",
      "Epoch 513/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5091e-05 - val_loss: 1.7022e-05\n",
      "Epoch 514/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4946e-05 - val_loss: 1.6818e-05\n",
      "Epoch 515/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.4490e-05 - val_loss: 1.7300e-05\n",
      "Epoch 516/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4799e-05 - val_loss: 1.6224e-05\n",
      "Epoch 517/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5474e-05 - val_loss: 1.5182e-05\n",
      "Epoch 518/1000\n",
      "871/871 [==============================] - 0s 113us/step - loss: 1.7323e-05 - val_loss: 1.6591e-05\n",
      "Epoch 519/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5645e-05 - val_loss: 1.8659e-05\n",
      "Epoch 520/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4606e-05 - val_loss: 1.7551e-05\n",
      "Epoch 521/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4469e-05 - val_loss: 1.8735e-05\n",
      "Epoch 522/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4240e-05 - val_loss: 1.5242e-05\n",
      "Epoch 523/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.4804e-05 - val_loss: 2.0606e-05\n",
      "Epoch 524/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.5265e-05 - val_loss: 2.3529e-05\n",
      "Epoch 525/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.5415e-05 - val_loss: 3.2252e-05\n",
      "Epoch 526/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.6470e-05 - val_loss: 3.6389e-05\n",
      "Epoch 527/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8033e-05 - val_loss: 4.0092e-05\n",
      "Epoch 528/1000\n",
      "871/871 [==============================] - 0s 93us/step - loss: 1.7907e-05 - val_loss: 4.3728e-05\n",
      "Epoch 529/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.9464e-05 - val_loss: 4.5042e-05\n",
      "Epoch 530/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.9817e-05 - val_loss: 3.1642e-05\n",
      "Epoch 531/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6926e-05 - val_loss: 2.7967e-05\n",
      "Epoch 532/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6568e-05 - val_loss: 2.4726e-05\n",
      "Epoch 533/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6274e-05 - val_loss: 2.3872e-05\n",
      "Epoch 534/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5206e-05 - val_loss: 2.1342e-05\n",
      "Epoch 535/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4502e-05 - val_loss: 1.7881e-05\n",
      "Epoch 536/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4366e-05 - val_loss: 1.5048e-05\n",
      "Epoch 537/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5699e-05 - val_loss: 1.4136e-05\n",
      "Epoch 538/1000\n",
      "871/871 [==============================] - 0s 119us/step - loss: 1.7670e-05 - val_loss: 1.4448e-05\n",
      "Epoch 539/1000\n",
      "871/871 [==============================] - 0s 95us/step - loss: 1.8281e-05 - val_loss: 1.4161e-05\n",
      "Epoch 540/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5609e-05 - val_loss: 1.4062e-05\n",
      "Epoch 541/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6059e-05 - val_loss: 1.8080e-05\n",
      "Epoch 542/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4247e-05 - val_loss: 2.3267e-05\n",
      "Epoch 543/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4420e-05 - val_loss: 2.6958e-05\n",
      "Epoch 544/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.5848e-05 - val_loss: 2.6285e-05\n",
      "Epoch 545/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5051e-05 - val_loss: 2.6398e-05\n",
      "Epoch 546/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.4599e-05 - val_loss: 2.4814e-05\n",
      "Epoch 547/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.5119e-05 - val_loss: 2.5735e-05\n",
      "Epoch 548/1000\n",
      "871/871 [==============================] - 0s 121us/step - loss: 1.4573e-05 - val_loss: 2.2359e-05\n",
      "Epoch 549/1000\n",
      "871/871 [==============================] - 0s 114us/step - loss: 1.4386e-05 - val_loss: 1.6435e-05\n",
      "Epoch 550/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.4523e-05 - val_loss: 1.4752e-05\n",
      "Epoch 551/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5414e-05 - val_loss: 1.4660e-05\n",
      "Epoch 552/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5722e-05 - val_loss: 1.5028e-05\n",
      "Epoch 553/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4530e-05 - val_loss: 1.5514e-05\n",
      "Epoch 554/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.4453e-05 - val_loss: 1.5180e-05\n",
      "Epoch 555/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5414e-05 - val_loss: 1.4072e-05\n",
      "Epoch 556/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6267e-05 - val_loss: 1.4968e-05\n",
      "Epoch 557/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5262e-05 - val_loss: 1.6931e-05\n",
      "Epoch 558/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.4465e-05 - val_loss: 1.9450e-05\n",
      "Epoch 559/1000\n",
      "871/871 [==============================] - 0s 100us/step - loss: 1.3990e-05 - val_loss: 1.9304e-05\n",
      "Epoch 560/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3866e-05 - val_loss: 1.6955e-05\n",
      "Epoch 561/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3986e-05 - val_loss: 1.6869e-05\n",
      "Epoch 562/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4481e-05 - val_loss: 2.1167e-05\n",
      "Epoch 563/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4026e-05 - val_loss: 1.9194e-05\n",
      "Epoch 564/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.4402e-05 - val_loss: 1.5611e-05\n",
      "Epoch 565/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.3934e-05 - val_loss: 1.8281e-05\n",
      "Epoch 566/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3966e-05 - val_loss: 1.5736e-05\n",
      "Epoch 567/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4002e-05 - val_loss: 1.7131e-05\n",
      "Epoch 568/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3877e-05 - val_loss: 1.6123e-05\n",
      "Epoch 569/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871/871 [==============================] - 0s 116us/step - loss: 1.4123e-05 - val_loss: 1.4051e-05\n",
      "Epoch 570/1000\n",
      "871/871 [==============================] - 0s 95us/step - loss: 1.5157e-05 - val_loss: 1.6909e-05\n",
      "Epoch 571/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3718e-05 - val_loss: 1.7283e-05\n",
      "Epoch 572/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3868e-05 - val_loss: 1.5752e-05\n",
      "Epoch 573/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3921e-05 - val_loss: 1.9791e-05\n",
      "Epoch 574/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4117e-05 - val_loss: 2.0474e-05\n",
      "Epoch 575/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4445e-05 - val_loss: 1.7762e-05\n",
      "Epoch 576/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3817e-05 - val_loss: 2.2736e-05\n",
      "Epoch 577/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4151e-05 - val_loss: 2.0401e-05\n",
      "Epoch 578/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3641e-05 - val_loss: 2.1796e-05\n",
      "Epoch 579/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5081e-05 - val_loss: 2.6528e-05\n",
      "Epoch 580/1000\n",
      "871/871 [==============================] - 0s 105us/step - loss: 1.5388e-05 - val_loss: 2.6005e-05\n",
      "Epoch 581/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5041e-05 - val_loss: 2.1972e-05\n",
      "Epoch 582/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3945e-05 - val_loss: 2.1950e-05\n",
      "Epoch 583/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3783e-05 - val_loss: 1.7929e-05\n",
      "Epoch 584/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.3915e-05 - val_loss: 1.6576e-05\n",
      "Epoch 585/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.3816e-05 - val_loss: 1.7632e-05\n",
      "Epoch 586/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.4547e-05 - val_loss: 1.9409e-05\n",
      "Epoch 587/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4076e-05 - val_loss: 2.0056e-05\n",
      "Epoch 588/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.4939e-05 - val_loss: 2.6594e-05\n",
      "Epoch 589/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4552e-05 - val_loss: 1.5599e-05\n",
      "Epoch 590/1000\n",
      "871/871 [==============================] - 0s 124us/step - loss: 1.4140e-05 - val_loss: 1.5477e-05\n",
      "Epoch 591/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.3905e-05 - val_loss: 1.6274e-05\n",
      "Epoch 592/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.4318e-05 - val_loss: 2.4884e-05\n",
      "Epoch 593/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5862e-05 - val_loss: 2.0889e-05\n",
      "Epoch 594/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.4293e-05 - val_loss: 2.3674e-05\n",
      "Epoch 595/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4676e-05 - val_loss: 2.0708e-05\n",
      "Epoch 596/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4220e-05 - val_loss: 1.5730e-05\n",
      "Epoch 597/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4160e-05 - val_loss: 1.4409e-05\n",
      "Epoch 598/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5479e-05 - val_loss: 2.0083e-05\n",
      "Epoch 599/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4118e-05 - val_loss: 2.0367e-05\n",
      "Epoch 600/1000\n",
      "871/871 [==============================] - ETA: 0s - loss: 1.3434e-0 - 0s 100us/step - loss: 1.3804e-05 - val_loss: 1.9980e-05\n",
      "Epoch 601/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.4368e-05 - val_loss: 2.2240e-05\n",
      "Epoch 602/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3973e-05 - val_loss: 1.8745e-05\n",
      "Epoch 603/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3520e-05 - val_loss: 1.4235e-05\n",
      "Epoch 604/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4263e-05 - val_loss: 1.4476e-05\n",
      "Epoch 605/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4434e-05 - val_loss: 1.4286e-05\n",
      "Epoch 606/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5002e-05 - val_loss: 1.9646e-05\n",
      "Epoch 607/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4368e-05 - val_loss: 1.9556e-05\n",
      "Epoch 608/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3856e-05 - val_loss: 1.7728e-05\n",
      "Epoch 609/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3568e-05 - val_loss: 1.7930e-05\n",
      "Epoch 610/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3542e-05 - val_loss: 1.5899e-05\n",
      "Epoch 611/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.3677e-05 - val_loss: 1.9879e-05\n",
      "Epoch 612/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3631e-05 - val_loss: 1.5902e-05\n",
      "Epoch 613/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3453e-05 - val_loss: 1.5454e-05\n",
      "Epoch 614/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3728e-05 - val_loss: 1.5894e-05\n",
      "Epoch 615/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4034e-05 - val_loss: 3.3378e-05\n",
      "Epoch 616/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6576e-05 - val_loss: 2.9243e-05\n",
      "Epoch 617/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.6319e-05 - val_loss: 2.0374e-05\n",
      "Epoch 618/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5179e-05 - val_loss: 1.6617e-05\n",
      "Epoch 619/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3580e-05 - val_loss: 1.3596e-05\n",
      "Epoch 620/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5005e-05 - val_loss: 1.5572e-05\n",
      "Epoch 621/1000\n",
      "871/871 [==============================] - 0s 111us/step - loss: 1.3843e-05 - val_loss: 1.3481e-05\n",
      "Epoch 622/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5894e-05 - val_loss: 1.8604e-05\n",
      "Epoch 623/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4448e-05 - val_loss: 2.0721e-05\n",
      "Epoch 624/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4891e-05 - val_loss: 2.3425e-05\n",
      "Epoch 625/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4113e-05 - val_loss: 2.1451e-05\n",
      "Epoch 626/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3604e-05 - val_loss: 2.6171e-05\n",
      "Epoch 627/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5300e-05 - val_loss: 1.6775e-05\n",
      "Epoch 628/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4110e-05 - val_loss: 1.5819e-05\n",
      "Epoch 629/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3442e-05 - val_loss: 1.4145e-05\n",
      "Epoch 630/1000\n",
      "871/871 [==============================] - 0s 119us/step - loss: 1.3887e-05 - val_loss: 1.6942e-05\n",
      "Epoch 631/1000\n",
      "871/871 [==============================] - 0s 123us/step - loss: 1.3453e-05 - val_loss: 1.5641e-05\n",
      "Epoch 632/1000\n",
      "871/871 [==============================] - 0s 96us/step - loss: 1.3317e-05 - val_loss: 2.3839e-05\n",
      "Epoch 633/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.4858e-05 - val_loss: 2.4429e-05\n",
      "Epoch 634/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7137e-05 - val_loss: 1.7652e-05\n",
      "Epoch 635/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.4740e-05 - val_loss: 1.4313e-05\n",
      "Epoch 636/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4045e-05 - val_loss: 1.9239e-05\n",
      "Epoch 637/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.3561e-05 - val_loss: 1.6452e-05\n",
      "Epoch 638/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3690e-05 - val_loss: 1.4482e-05\n",
      "Epoch 639/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3446e-05 - val_loss: 1.4107e-05\n",
      "Epoch 640/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4621e-05 - val_loss: 1.8181e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 641/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4421e-05 - val_loss: 2.9825e-05\n",
      "Epoch 642/1000\n",
      "871/871 [==============================] - 0s 106us/step - loss: 1.5729e-05 - val_loss: 2.0433e-05\n",
      "Epoch 643/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5094e-05 - val_loss: 1.3737e-05\n",
      "Epoch 644/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4108e-05 - val_loss: 1.3817e-05\n",
      "Epoch 645/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5270e-05 - val_loss: 1.3933e-05\n",
      "Epoch 646/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3931e-05 - val_loss: 1.6390e-05\n",
      "Epoch 647/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3976e-05 - val_loss: 1.7764e-05\n",
      "Epoch 648/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3316e-05 - val_loss: 1.6122e-05\n",
      "Epoch 649/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3651e-05 - val_loss: 1.4673e-05\n",
      "Epoch 650/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4714e-05 - val_loss: 3.2284e-05\n",
      "Epoch 651/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.5854e-05 - val_loss: 2.0302e-05\n",
      "Epoch 652/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4655e-05 - val_loss: 1.5605e-05\n",
      "Epoch 653/1000\n",
      "871/871 [==============================] - ETA: 0s - loss: 1.3718e-0 - 0s 90us/step - loss: 1.3564e-05 - val_loss: 2.0042e-05\n",
      "Epoch 654/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.3722e-05 - val_loss: 1.6414e-05\n",
      "Epoch 655/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3805e-05 - val_loss: 1.7467e-05\n",
      "Epoch 656/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3266e-05 - val_loss: 1.9660e-05\n",
      "Epoch 657/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4020e-05 - val_loss: 1.5436e-05\n",
      "Epoch 658/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3447e-05 - val_loss: 1.9293e-05\n",
      "Epoch 659/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4643e-05 - val_loss: 1.8603e-05\n",
      "Epoch 660/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3624e-05 - val_loss: 2.3612e-05\n",
      "Epoch 661/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4585e-05 - val_loss: 1.3513e-05\n",
      "Epoch 662/1000\n",
      "871/871 [==============================] - 0s 103us/step - loss: 1.5171e-05 - val_loss: 1.3477e-05\n",
      "Epoch 663/1000\n",
      "871/871 [==============================] - 0s 117us/step - loss: 1.3662e-05 - val_loss: 1.3294e-05\n",
      "Epoch 664/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4431e-05 - val_loss: 1.5182e-05\n",
      "Epoch 665/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5686e-05 - val_loss: 2.7076e-05\n",
      "Epoch 666/1000\n",
      "871/871 [==============================] - ETA: 0s - loss: 1.8864e-0 - 0s 108us/step - loss: 1.5060e-05 - val_loss: 1.5230e-05\n",
      "Epoch 667/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3617e-05 - val_loss: 1.4185e-05\n",
      "Epoch 668/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3369e-05 - val_loss: 1.8360e-05\n",
      "Epoch 669/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5116e-05 - val_loss: 2.1382e-05\n",
      "Epoch 670/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5651e-05 - val_loss: 1.3273e-05\n",
      "Epoch 671/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5270e-05 - val_loss: 1.3344e-05\n",
      "Epoch 672/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4335e-05 - val_loss: 1.5009e-05\n",
      "Epoch 673/1000\n",
      "871/871 [==============================] - 0s 121us/step - loss: 1.3930e-05 - val_loss: 2.4084e-05\n",
      "Epoch 674/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4014e-05 - val_loss: 1.7428e-05\n",
      "Epoch 675/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3317e-05 - val_loss: 1.4703e-05\n",
      "Epoch 676/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.3298e-05 - val_loss: 1.8460e-05\n",
      "Epoch 677/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3459e-05 - val_loss: 1.7666e-05\n",
      "Epoch 678/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3297e-05 - val_loss: 1.8891e-05\n",
      "Epoch 679/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3647e-05 - val_loss: 1.5615e-05\n",
      "Epoch 680/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3277e-05 - val_loss: 1.8604e-05\n",
      "Epoch 681/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3784e-05 - val_loss: 1.5751e-05\n",
      "Epoch 682/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3650e-05 - val_loss: 1.5269e-05\n",
      "Epoch 683/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3295e-05 - val_loss: 1.6657e-05\n",
      "Epoch 684/1000\n",
      "871/871 [==============================] - 0s 117us/step - loss: 1.3142e-05 - val_loss: 1.7864e-05\n",
      "Epoch 685/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4430e-05 - val_loss: 1.3453e-05\n",
      "Epoch 686/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5557e-05 - val_loss: 1.8087e-05\n",
      "Epoch 687/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6815e-05 - val_loss: 2.4120e-05\n",
      "Epoch 688/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5628e-05 - val_loss: 1.6864e-05\n",
      "Epoch 689/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3895e-05 - val_loss: 1.3955e-05\n",
      "Epoch 690/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.3964e-05 - val_loss: 1.4504e-05\n",
      "Epoch 691/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3486e-05 - val_loss: 2.2408e-05\n",
      "Epoch 692/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5476e-05 - val_loss: 1.3407e-05\n",
      "Epoch 693/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4263e-05 - val_loss: 1.4096e-05\n",
      "Epoch 694/1000\n",
      "871/871 [==============================] - 0s 104us/step - loss: 1.4237e-05 - val_loss: 1.9224e-05\n",
      "Epoch 695/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4820e-05 - val_loss: 2.0508e-05\n",
      "Epoch 696/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7365e-05 - val_loss: 1.9160e-05\n",
      "Epoch 697/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 2.4504e-05 - val_loss: 2.8761e-05\n",
      "Epoch 698/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.2181e-05 - val_loss: 3.0957e-05\n",
      "Epoch 699/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 2.2174e-05 - val_loss: 1.3701e-05\n",
      "Epoch 700/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7416e-05 - val_loss: 1.3745e-05\n",
      "Epoch 701/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4270e-05 - val_loss: 2.4182e-05\n",
      "Epoch 702/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4416e-05 - val_loss: 1.3034e-05\n",
      "Epoch 703/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5929e-05 - val_loss: 1.3146e-05\n",
      "Epoch 704/1000\n",
      "871/871 [==============================] - 0s 116us/step - loss: 1.4935e-05 - val_loss: 2.0544e-05\n",
      "Epoch 705/1000\n",
      "871/871 [==============================] - 0s 98us/step - loss: 1.4655e-05 - val_loss: 1.5820e-05\n",
      "Epoch 706/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4088e-05 - val_loss: 1.7934e-05\n",
      "Epoch 707/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4279e-05 - val_loss: 1.3119e-05\n",
      "Epoch 708/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4836e-05 - val_loss: 2.4288e-05\n",
      "Epoch 709/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.5050e-05 - val_loss: 2.0486e-05\n",
      "Epoch 710/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6574e-05 - val_loss: 1.7954e-05\n",
      "Epoch 711/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.0453e-05 - val_loss: 1.7647e-05\n",
      "Epoch 712/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7093e-05 - val_loss: 1.7499e-05\n",
      "Epoch 713/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4553e-05 - val_loss: 1.3794e-05\n",
      "Epoch 714/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3672e-05 - val_loss: 1.3666e-05\n",
      "Epoch 715/1000\n",
      "871/871 [==============================] - 0s 117us/step - loss: 1.3423e-05 - val_loss: 1.3334e-05\n",
      "Epoch 716/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4272e-05 - val_loss: 1.8811e-05\n",
      "Epoch 717/1000\n",
      "871/871 [==============================] - 0s 197us/step - loss: 1.3631e-05 - val_loss: 1.5768e-05\n",
      "Epoch 718/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5720e-05 - val_loss: 2.0684e-05\n",
      "Epoch 719/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.0684e-05 - val_loss: 1.3348e-05\n",
      "Epoch 720/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.0592e-05 - val_loss: 2.7627e-05\n",
      "Epoch 721/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6267e-05 - val_loss: 1.6383e-05\n",
      "Epoch 722/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3820e-05 - val_loss: 1.3291e-05\n",
      "Epoch 723/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4716e-05 - val_loss: 1.3833e-05\n",
      "Epoch 724/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4723e-05 - val_loss: 4.2041e-05\n",
      "Epoch 725/1000\n",
      "871/871 [==============================] - 0s 110us/step - loss: 1.9162e-05 - val_loss: 1.5834e-05\n",
      "Epoch 726/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7174e-05 - val_loss: 1.5787e-05\n",
      "Epoch 727/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8642e-05 - val_loss: 2.2203e-05\n",
      "Epoch 728/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4043e-05 - val_loss: 2.5828e-05\n",
      "Epoch 729/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4932e-05 - val_loss: 1.3552e-05\n",
      "Epoch 730/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4037e-05 - val_loss: 1.5001e-05\n",
      "Epoch 731/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3196e-05 - val_loss: 1.7575e-05\n",
      "Epoch 732/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4279e-05 - val_loss: 1.4569e-05\n",
      "Epoch 733/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3197e-05 - val_loss: 1.3681e-05\n",
      "Epoch 734/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3279e-05 - val_loss: 1.4975e-05\n",
      "Epoch 735/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3392e-05 - val_loss: 1.5805e-05\n",
      "Epoch 736/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.3192e-05 - val_loss: 2.0967e-05\n",
      "Epoch 737/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3416e-05 - val_loss: 2.0378e-05\n",
      "Epoch 738/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3405e-05 - val_loss: 1.5898e-05\n",
      "Epoch 739/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3067e-05 - val_loss: 1.3227e-05\n",
      "Epoch 740/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4104e-05 - val_loss: 3.1175e-05\n",
      "Epoch 741/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.6733e-05 - val_loss: 1.2893e-05\n",
      "Epoch 742/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5221e-05 - val_loss: 1.2879e-05\n",
      "Epoch 743/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5580e-05 - val_loss: 1.6910e-05\n",
      "Epoch 744/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.2981e-05 - val_loss: 1.3069e-05\n",
      "Epoch 745/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4068e-05 - val_loss: 2.1745e-05\n",
      "Epoch 746/1000\n",
      "871/871 [==============================] - 0s 123us/step - loss: 1.6244e-05 - val_loss: 1.3559e-05\n",
      "Epoch 747/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6232e-05 - val_loss: 1.3755e-05\n",
      "Epoch 748/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5230e-05 - val_loss: 2.1000e-05\n",
      "Epoch 749/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4424e-05 - val_loss: 1.8038e-05\n",
      "Epoch 750/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4659e-05 - val_loss: 1.2942e-05\n",
      "Epoch 751/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6146e-05 - val_loss: 1.3217e-05\n",
      "Epoch 752/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3712e-05 - val_loss: 1.3341e-05\n",
      "Epoch 753/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.3186e-05 - val_loss: 1.6627e-05\n",
      "Epoch 754/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3972e-05 - val_loss: 1.8671e-05\n",
      "Epoch 755/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6560e-05 - val_loss: 1.2989e-05\n",
      "Epoch 756/1000\n",
      "871/871 [==============================] - 0s 114us/step - loss: 1.4459e-05 - val_loss: 2.7788e-05\n",
      "Epoch 757/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 1.5860e-05 - val_loss: 1.4170e-05\n",
      "Epoch 758/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.4840e-05 - val_loss: 1.3089e-05\n",
      "Epoch 759/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.1186e-05 - val_loss: 3.0008e-05\n",
      "Epoch 760/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.0453e-05 - val_loss: 1.7697e-05\n",
      "Epoch 761/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.9416e-05 - val_loss: 2.5507e-05\n",
      "Epoch 762/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.1943e-05 - val_loss: 1.5860e-05\n",
      "Epoch 763/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.9870e-05 - val_loss: 1.4775e-05\n",
      "Epoch 764/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.9602e-05 - val_loss: 2.9610e-05\n",
      "Epoch 765/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8280e-05 - val_loss: 1.5436e-05\n",
      "Epoch 766/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.0163e-05 - val_loss: 1.6332e-05\n",
      "Epoch 767/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.5279e-05 - val_loss: 2.6149e-05\n",
      "Epoch 768/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.4232e-05 - val_loss: 1.4875e-05\n",
      "Epoch 769/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4000e-05 - val_loss: 1.2982e-05\n",
      "Epoch 770/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4989e-05 - val_loss: 1.8623e-05\n",
      "Epoch 771/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3289e-05 - val_loss: 1.4395e-05\n",
      "Epoch 772/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3025e-05 - val_loss: 1.7632e-05\n",
      "Epoch 773/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5100e-05 - val_loss: 2.0952e-05\n",
      "Epoch 774/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4054e-05 - val_loss: 1.2971e-05\n",
      "Epoch 775/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.3717e-05 - val_loss: 1.5048e-05\n",
      "Epoch 776/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.2955e-05 - val_loss: 1.4673e-05\n",
      "Epoch 777/1000\n",
      "871/871 [==============================] - 0s 95us/step - loss: 1.3163e-05 - val_loss: 1.8118e-05\n",
      "Epoch 778/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3367e-05 - val_loss: 1.3022e-05\n",
      "Epoch 779/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.4518e-05 - val_loss: 1.4047e-05\n",
      "Epoch 780/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3098e-05 - val_loss: 1.3220e-05\n",
      "Epoch 781/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4585e-05 - val_loss: 1.5352e-05\n",
      "Epoch 782/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3263e-05 - val_loss: 1.4602e-05\n",
      "Epoch 783/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3274e-05 - val_loss: 2.4022e-05\n",
      "Epoch 784/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "871/871 [==============================] - 0s 108us/step - loss: 1.3943e-05 - val_loss: 1.4992e-05\n",
      "Epoch 785/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4235e-05 - val_loss: 1.6698e-05\n",
      "Epoch 786/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3772e-05 - val_loss: 1.3096e-05\n",
      "Epoch 787/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.5860e-05 - val_loss: 2.7240e-05\n",
      "Epoch 788/1000\n",
      "871/871 [==============================] - 0s 92us/step - loss: 1.6355e-05 - val_loss: 1.3865e-05\n",
      "Epoch 789/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.3059e-05 - val_loss: 1.3033e-05\n",
      "Epoch 790/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4425e-05 - val_loss: 1.5327e-05\n",
      "Epoch 791/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4272e-05 - val_loss: 1.6559e-05\n",
      "Epoch 792/1000\n",
      "871/871 [==============================] - ETA: 0s - loss: 1.4742e-0 - 0s 90us/step - loss: 1.3781e-05 - val_loss: 1.4749e-05\n",
      "Epoch 793/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.3547e-05 - val_loss: 1.3088e-05\n",
      "Epoch 794/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.5206e-05 - val_loss: 2.9208e-05\n",
      "Epoch 795/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.8921e-05 - val_loss: 1.6777e-05\n",
      "Epoch 796/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6886e-05 - val_loss: 1.9880e-05\n",
      "Epoch 797/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5402e-05 - val_loss: 1.4314e-05\n",
      "Epoch 798/1000\n",
      "871/871 [==============================] - 0s 114us/step - loss: 1.3474e-05 - val_loss: 1.4039e-05\n",
      "Epoch 799/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.3147e-05 - val_loss: 1.9090e-05\n",
      "Epoch 800/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.2969e-05 - val_loss: 1.3092e-05\n",
      "Epoch 801/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4628e-05 - val_loss: 3.1517e-05\n",
      "Epoch 802/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7059e-05 - val_loss: 1.4467e-05\n",
      "Epoch 803/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8664e-05 - val_loss: 2.3602e-05\n",
      "Epoch 804/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5470e-05 - val_loss: 1.3021e-05\n",
      "Epoch 805/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.6149e-05 - val_loss: 3.5002e-05\n",
      "Epoch 806/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.1800e-05 - val_loss: 2.1953e-05\n",
      "Epoch 807/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.3683e-05 - val_loss: 3.1852e-05\n",
      "Epoch 808/1000\n",
      "871/871 [==============================] - 0s 105us/step - loss: 1.7209e-05 - val_loss: 1.3526e-05\n",
      "Epoch 809/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3561e-05 - val_loss: 2.7055e-05\n",
      "Epoch 810/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.4989e-05 - val_loss: 1.7300e-05\n",
      "Epoch 811/1000\n",
      "871/871 [==============================] - 0s 90us/step - loss: 1.3006e-05 - val_loss: 1.9318e-05\n",
      "Epoch 812/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5496e-05 - val_loss: 1.4274e-05\n",
      "Epoch 813/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.9570e-05 - val_loss: 1.5988e-05\n",
      "Epoch 814/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3025e-05 - val_loss: 1.6385e-05\n",
      "Epoch 815/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.2879e-05 - val_loss: 1.7984e-05\n",
      "Epoch 816/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4556e-05 - val_loss: 1.6002e-05\n",
      "Epoch 817/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3087e-05 - val_loss: 1.5715e-05\n",
      "Epoch 818/1000\n",
      "871/871 [==============================] - 0s 114us/step - loss: 1.2802e-05 - val_loss: 1.4592e-05\n",
      "Epoch 819/1000\n",
      "871/871 [==============================] - 0s 114us/step - loss: 1.2738e-05 - val_loss: 1.2966e-05\n",
      "Epoch 820/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3613e-05 - val_loss: 2.1960e-05\n",
      "Epoch 821/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4091e-05 - val_loss: 1.4575e-05\n",
      "Epoch 822/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3617e-05 - val_loss: 2.1173e-05\n",
      "Epoch 823/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.7561e-05 - val_loss: 1.4725e-05\n",
      "Epoch 824/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.9628e-05 - val_loss: 1.7937e-05\n",
      "Epoch 825/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.3467e-05 - val_loss: 1.4505e-05\n",
      "Epoch 826/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3694e-05 - val_loss: 3.8538e-05\n",
      "Epoch 827/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.9966e-05 - val_loss: 1.5907e-05\n",
      "Epoch 828/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6995e-05 - val_loss: 3.2558e-05\n",
      "Epoch 829/1000\n",
      "871/871 [==============================] - 0s 110us/step - loss: 2.1407e-05 - val_loss: 1.5821e-05\n",
      "Epoch 830/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7960e-05 - val_loss: 3.1467e-05\n",
      "Epoch 831/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.6917e-05 - val_loss: 1.4616e-05\n",
      "Epoch 832/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.2844e-05 - val_loss: 1.3072e-05\n",
      "Epoch 833/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3811e-05 - val_loss: 2.1665e-05\n",
      "Epoch 834/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.3330e-05 - val_loss: 1.4704e-05\n",
      "Epoch 835/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.2834e-05 - val_loss: 1.3766e-05\n",
      "Epoch 836/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.3383e-05 - val_loss: 1.2965e-05\n",
      "Epoch 837/1000\n",
      "871/871 [==============================] - 0s 133us/step - loss: 1.3797e-05 - val_loss: 1.4015e-05\n",
      "Epoch 838/1000\n",
      "871/871 [==============================] - 0s 124us/step - loss: 1.3610e-05 - val_loss: 2.7249e-05\n",
      "Epoch 839/1000\n",
      "871/871 [==============================] - 0s 124us/step - loss: 1.6198e-05 - val_loss: 1.3467e-05\n",
      "Epoch 840/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.5098e-05 - val_loss: 2.4328e-05\n",
      "Epoch 841/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.5162e-05 - val_loss: 1.6914e-05\n",
      "Epoch 842/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.4547e-05 - val_loss: 1.3724e-05\n",
      "Epoch 843/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 1.3533e-05 - val_loss: 1.8901e-05\n",
      "Epoch 844/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.4908e-05 - val_loss: 1.3926e-05\n",
      "Epoch 845/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.2826e-05 - val_loss: 2.2559e-05\n",
      "Epoch 846/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.3252e-05 - val_loss: 1.5485e-05\n",
      "Epoch 847/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.3082e-05 - val_loss: 3.0258e-05\n",
      "Epoch 848/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 1.7275e-05 - val_loss: 1.4364e-05\n",
      "Epoch 849/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.2763e-05 - val_loss: 1.5129e-05\n",
      "Epoch 850/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.2994e-05 - val_loss: 1.7187e-05\n",
      "Epoch 851/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.3228e-05 - val_loss: 2.5708e-05\n",
      "Epoch 852/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.8955e-05 - val_loss: 1.4343e-05\n",
      "Epoch 853/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.3687e-05 - val_loss: 2.3566e-05\n",
      "Epoch 854/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 1.5385e-05 - val_loss: 1.3269e-05\n",
      "Epoch 855/1000\n",
      "871/871 [==============================] - 0s 133us/step - loss: 1.6406e-05 - val_loss: 1.6846e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.3320e-05 - val_loss: 1.8939e-05\n",
      "Epoch 857/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 1.4525e-05 - val_loss: 1.3452e-05\n",
      "Epoch 858/1000\n",
      "871/871 [==============================] - 0s 120us/step - loss: 1.4082e-05 - val_loss: 1.3054e-05\n",
      "Epoch 859/1000\n",
      "871/871 [==============================] - 0s 110us/step - loss: 1.3820e-05 - val_loss: 2.8622e-05\n",
      "Epoch 860/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.7371e-05 - val_loss: 1.3689e-05\n",
      "Epoch 861/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.8034e-05 - val_loss: 1.5059e-05\n",
      "Epoch 862/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 1.4276e-05 - val_loss: 1.3355e-05\n",
      "Epoch 863/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.6353e-05 - val_loss: 1.9554e-05\n",
      "Epoch 864/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 2.0071e-05 - val_loss: 2.5550e-05\n",
      "Epoch 865/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.5701e-05 - val_loss: 1.3430e-05\n",
      "Epoch 866/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.5573e-05 - val_loss: 3.5693e-05\n",
      "Epoch 867/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.8948e-05 - val_loss: 1.3534e-05\n",
      "Epoch 868/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 1.5667e-05 - val_loss: 1.6597e-05\n",
      "Epoch 869/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.3585e-05 - val_loss: 1.6756e-05\n",
      "Epoch 870/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.3448e-05 - val_loss: 1.5263e-05\n",
      "Epoch 871/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.2869e-05 - val_loss: 1.3019e-05\n",
      "Epoch 872/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3221e-05 - val_loss: 1.4327e-05\n",
      "Epoch 873/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.3076e-05 - val_loss: 2.1690e-05\n",
      "Epoch 874/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.3593e-05 - val_loss: 1.3494e-05\n",
      "Epoch 875/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 1.3328e-05 - val_loss: 1.9131e-05\n",
      "Epoch 876/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.3025e-05 - val_loss: 1.3736e-05\n",
      "Epoch 877/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.3667e-05 - val_loss: 1.4467e-05\n",
      "Epoch 878/1000\n",
      "871/871 [==============================] - 0s 134us/step - loss: 1.3953e-05 - val_loss: 1.3039e-05\n",
      "Epoch 879/1000\n",
      "871/871 [==============================] - 0s 95us/step - loss: 1.4887e-05 - val_loss: 1.4384e-05\n",
      "Epoch 880/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.3008e-05 - val_loss: 1.3453e-05\n",
      "Epoch 881/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.4203e-05 - val_loss: 1.7782e-05\n",
      "Epoch 882/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 1.3658e-05 - val_loss: 1.5360e-05\n",
      "Epoch 883/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.4637e-05 - val_loss: 1.3806e-05\n",
      "Epoch 884/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.7493e-05 - val_loss: 3.1674e-05\n",
      "Epoch 885/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.7350e-05 - val_loss: 1.2948e-05\n",
      "Epoch 886/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.3370e-05 - val_loss: 1.4573e-05\n",
      "Epoch 887/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.3946e-05 - val_loss: 1.8036e-05\n",
      "Epoch 888/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.5273e-05 - val_loss: 1.2907e-05\n",
      "Epoch 889/1000\n",
      "871/871 [==============================] - 0s 102us/step - loss: 1.6575e-05 - val_loss: 1.3390e-05\n",
      "Epoch 890/1000\n",
      "871/871 [==============================] - 0s 135us/step - loss: 1.8567e-05 - val_loss: 2.9582e-05\n",
      "Epoch 891/1000\n",
      "871/871 [==============================] - 0s 111us/step - loss: 1.5761e-05 - val_loss: 1.3842e-05\n",
      "Epoch 892/1000\n",
      "871/871 [==============================] - 0s 109us/step - loss: 1.8282e-05 - val_loss: 1.3377e-05\n",
      "Epoch 893/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.9542e-05 - val_loss: 4.5113e-05\n",
      "Epoch 894/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 2.4884e-05 - val_loss: 1.3268e-05\n",
      "Epoch 895/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 2.0427e-05 - val_loss: 1.4030e-05\n",
      "Epoch 896/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.8204e-05 - val_loss: 2.7119e-05\n",
      "Epoch 897/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.7620e-05 - val_loss: 1.3221e-05\n",
      "Epoch 898/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 2.0102e-05 - val_loss: 1.3428e-05\n",
      "Epoch 899/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.7764e-05 - val_loss: 2.4342e-05\n",
      "Epoch 900/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.5359e-05 - val_loss: 1.6563e-05\n",
      "Epoch 901/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 2.1517e-05 - val_loss: 2.8506e-05\n",
      "Epoch 902/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 2.2535e-05 - val_loss: 1.5628e-05\n",
      "Epoch 903/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.8900e-05 - val_loss: 2.3538e-05\n",
      "Epoch 904/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 2.2088e-05 - val_loss: 2.9838e-05\n",
      "Epoch 905/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.8504e-05 - val_loss: 1.4493e-05\n",
      "Epoch 906/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.4172e-05 - val_loss: 1.3433e-05\n",
      "Epoch 907/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.4389e-05 - val_loss: 2.2550e-05\n",
      "Epoch 908/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.4726e-05 - val_loss: 1.4478e-05\n",
      "Epoch 909/1000\n",
      "871/871 [==============================] - 0s 118us/step - loss: 1.2675e-05 - val_loss: 1.3248e-05\n",
      "Epoch 910/1000\n",
      "871/871 [==============================] - 0s 95us/step - loss: 1.4861e-05 - val_loss: 1.3529e-05\n",
      "Epoch 911/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.4115e-05 - val_loss: 2.1177e-05\n",
      "Epoch 912/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 2.1358e-05 - val_loss: 2.3494e-05\n",
      "Epoch 913/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.5445e-05 - val_loss: 1.4078e-05\n",
      "Epoch 914/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.2850e-05 - val_loss: 1.3213e-05\n",
      "Epoch 915/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.4594e-05 - val_loss: 2.9901e-05\n",
      "Epoch 916/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 1.7059e-05 - val_loss: 1.3258e-05\n",
      "Epoch 917/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.7909e-05 - val_loss: 1.3275e-05\n",
      "Epoch 918/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.6813e-05 - val_loss: 2.6891e-05\n",
      "Epoch 919/1000\n",
      "871/871 [==============================] - 0s 120us/step - loss: 1.5857e-05 - val_loss: 1.3777e-05\n",
      "Epoch 920/1000\n",
      "871/871 [==============================] - 0s 109us/step - loss: 1.9441e-05 - val_loss: 1.8389e-05\n",
      "Epoch 921/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 1.9761e-05 - val_loss: 2.5232e-05\n",
      "Epoch 922/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 1.4996e-05 - val_loss: 1.4642e-05\n",
      "Epoch 923/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.2997e-05 - val_loss: 2.1689e-05\n",
      "Epoch 924/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.4391e-05 - val_loss: 1.3547e-05\n",
      "Epoch 925/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.3137e-05 - val_loss: 1.4848e-05\n",
      "Epoch 926/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.7586e-05 - val_loss: 3.7836e-05\n",
      "Epoch 927/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.0724e-05 - val_loss: 1.3981e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 928/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 1.7382e-05 - val_loss: 1.8314e-05\n",
      "Epoch 929/1000\n",
      "871/871 [==============================] - 0s 127us/step - loss: 1.5251e-05 - val_loss: 1.9633e-05\n",
      "Epoch 930/1000\n",
      "871/871 [==============================] - 0s 102us/step - loss: 1.3826e-05 - val_loss: 1.3083e-05\n",
      "Epoch 931/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.5111e-05 - val_loss: 3.1756e-05\n",
      "Epoch 932/1000\n",
      "871/871 [==============================] - 0s 97us/step - loss: 2.1937e-05 - val_loss: 2.3251e-05\n",
      "Epoch 933/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 2.9101e-05 - val_loss: 2.8849e-05\n",
      "Epoch 934/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 2.9926e-05 - val_loss: 1.6072e-05\n",
      "Epoch 935/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.9857e-05 - val_loss: 3.1421e-05\n",
      "Epoch 936/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.8998e-05 - val_loss: 1.4105e-05\n",
      "Epoch 937/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 1.6942e-05 - val_loss: 1.9596e-05\n",
      "Epoch 938/1000\n",
      "871/871 [==============================] - 0s 115us/step - loss: 2.2221e-05 - val_loss: 3.8940e-05\n",
      "Epoch 939/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.0703e-05 - val_loss: 2.0771e-05\n",
      "Epoch 940/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.6551e-05 - val_loss: 2.2123e-05\n",
      "Epoch 941/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.7415e-05 - val_loss: 3.8153e-05\n",
      "Epoch 942/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.1937e-05 - val_loss: 2.4813e-05\n",
      "Epoch 943/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.6602e-05 - val_loss: 3.2534e-05\n",
      "Epoch 944/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 3.6397e-05 - val_loss: 5.9936e-05\n",
      "Epoch 945/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.5213e-05 - val_loss: 2.1986e-05\n",
      "Epoch 946/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.0137e-05 - val_loss: 2.0148e-05\n",
      "Epoch 947/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4540e-05 - val_loss: 2.1350e-05\n",
      "Epoch 948/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6924e-05 - val_loss: 1.3319e-05\n",
      "Epoch 949/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3973e-05 - val_loss: 1.3151e-05\n",
      "Epoch 950/1000\n",
      "871/871 [==============================] - 0s 119us/step - loss: 1.6239e-05 - val_loss: 4.9995e-05\n",
      "Epoch 951/1000\n",
      "871/871 [==============================] - 0s 99us/step - loss: 2.4941e-05 - val_loss: 1.4296e-05\n",
      "Epoch 952/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.1819e-05 - val_loss: 1.3346e-05\n",
      "Epoch 953/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5139e-05 - val_loss: 3.3632e-05\n",
      "Epoch 954/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8926e-05 - val_loss: 2.4904e-05\n",
      "Epoch 955/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8021e-05 - val_loss: 1.8715e-05\n",
      "Epoch 956/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.9535e-05 - val_loss: 2.1219e-05\n",
      "Epoch 957/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.2124e-05 - val_loss: 2.0897e-05\n",
      "Epoch 958/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.2423e-05 - val_loss: 1.9246e-05\n",
      "Epoch 959/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.7735e-05 - val_loss: 4.4559e-05\n",
      "Epoch 960/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.3077e-05 - val_loss: 1.4357e-05\n",
      "Epoch 961/1000\n",
      "871/871 [==============================] - 0s 116us/step - loss: 1.6250e-05 - val_loss: 1.3611e-05\n",
      "Epoch 962/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.7033e-05 - val_loss: 2.0596e-05\n",
      "Epoch 963/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5917e-05 - val_loss: 1.9428e-05\n",
      "Epoch 964/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7355e-05 - val_loss: 1.8142e-05\n",
      "Epoch 965/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.3364e-05 - val_loss: 2.8903e-05\n",
      "Epoch 966/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.8868e-05 - val_loss: 1.3513e-05\n",
      "Epoch 967/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5458e-05 - val_loss: 1.3977e-05\n",
      "Epoch 968/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3631e-05 - val_loss: 1.8213e-05\n",
      "Epoch 969/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5225e-05 - val_loss: 1.5503e-05\n",
      "Epoch 970/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.9303e-05 - val_loss: 1.8075e-05\n",
      "Epoch 971/1000\n",
      "871/871 [==============================] - 0s 114us/step - loss: 1.3739e-05 - val_loss: 2.0002e-05\n",
      "Epoch 972/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.5190e-05 - val_loss: 2.2606e-05\n",
      "Epoch 973/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3736e-05 - val_loss: 1.4092e-05\n",
      "Epoch 974/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3399e-05 - val_loss: 1.3309e-05\n",
      "Epoch 975/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.7101e-05 - val_loss: 2.6647e-05\n",
      "Epoch 976/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.9880e-05 - val_loss: 2.5523e-05\n",
      "Epoch 977/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.0353e-05 - val_loss: 1.3828e-05\n",
      "Epoch 978/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.8875e-05 - val_loss: 2.7482e-05\n",
      "Epoch 979/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6718e-05 - val_loss: 2.0822e-05\n",
      "Epoch 980/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.6192e-05 - val_loss: 1.4194e-05\n",
      "Epoch 981/1000\n",
      "871/871 [==============================] - 0s 116us/step - loss: 1.6365e-05 - val_loss: 1.7173e-05\n",
      "Epoch 982/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3435e-05 - val_loss: 1.5528e-05\n",
      "Epoch 983/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3720e-05 - val_loss: 1.3333e-05\n",
      "Epoch 984/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.8052e-05 - val_loss: 3.8676e-05\n",
      "Epoch 985/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.0498e-05 - val_loss: 1.8416e-05\n",
      "Epoch 986/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5140e-05 - val_loss: 1.9569e-05\n",
      "Epoch 987/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.4479e-05 - val_loss: 1.6043e-05\n",
      "Epoch 988/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.0609e-05 - val_loss: 4.4454e-05\n",
      "Epoch 989/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.4603e-05 - val_loss: 1.9375e-05\n",
      "Epoch 990/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.9647e-05 - val_loss: 2.6021e-05\n",
      "Epoch 991/1000\n",
      "871/871 [==============================] - 0s 131us/step - loss: 2.9771e-05 - val_loss: 1.6451e-05\n",
      "Epoch 992/1000\n",
      "871/871 [==============================] - 0s 116us/step - loss: 1.6115e-05 - val_loss: 2.0843e-05\n",
      "Epoch 993/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.3454e-05 - val_loss: 1.6179e-05\n",
      "Epoch 994/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3373e-05 - val_loss: 1.3994e-05\n",
      "Epoch 995/1000\n",
      "871/871 [==============================] - 0s 126us/step - loss: 1.2635e-05 - val_loss: 2.5693e-05\n",
      "Epoch 996/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.5256e-05 - val_loss: 1.8113e-05\n",
      "Epoch 997/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3771e-05 - val_loss: 1.6462e-05\n",
      "Epoch 998/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 2.2519e-05 - val_loss: 1.3213e-05\n",
      "Epoch 999/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.4520e-05 - val_loss: 2.2923e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000/1000\n",
      "871/871 [==============================] - 0s 108us/step - loss: 1.3778e-05 - val_loss: 1.6391e-05\n"
     ]
    }
   ],
   "source": [
    "model, train_history = model(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.78601574897766\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "running_time = end-start\n",
    "print(running_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fb0aa50f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_train_history(train_history,'loss','val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
